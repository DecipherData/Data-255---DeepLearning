{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LMPXauF8rALv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9189f9b-1c7f-4d70-b38c-c129953e1cb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "id": "EwxEGxiyxq8C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d03c086-9357-4d42-addb-e10f0ab23ce2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TdAFDx0drwo",
        "outputId": "84b69039-012e-4498-9e64-8f7b487dfed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Nov 30 16:15:28 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading Libraries**"
      ],
      "metadata": {
        "id": "1vhup0RLKjR4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjlqeC9YSyUr",
        "outputId": "7a3504af-db70-47fa-ed69-e85f4730f77d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, SimpleRNN, LSTM, GRU, Bidirectional, Dense, Flatten,Dropout\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "import time\n",
        "import string\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "import gensim.downloader as api\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from nltk.corpus import stopwords\n",
        "import contractions  # Library for expanding contractions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Drive**"
      ],
      "metadata": {
        "id": "OBP-GypkKoKo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkXdG98JUa33",
        "outputId": "63e4ae17-6d96-4b63-f5da-dbc044d6dc2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-JayvAUKUoUt"
      },
      "outputs": [],
      "source": [
        "HOME = '/content/drive/MyDrive/DeepLearning/HW/HW4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NRkMIbigUjcB",
        "outputId": "0fcde538-0e64-44dd-fb59-7536864e959e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/DeepLearning/HW/HW4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import os\n",
        "os.chdir(HOME)\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1.**"
      ],
      "metadata": {
        "id": "c1lLn4dNKtBF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaning IMDB Data**"
      ],
      "metadata": {
        "id": "LL7WcI8BK9QS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2ekGRiiSyNe"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(r'/content/drive/MyDrive/DeepLearning/HW/HW3/IMDB Dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cXEPtzrMV8nf",
        "outputId": "695f7b99-5e09-4f3a-dc8a-708d5551c623"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6d84049-35ae-4835-9c09-c1df15749866\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6d84049-35ae-4835-9c09-c1df15749866')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c6d84049-35ae-4835-9c09-c1df15749866 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c6d84049-35ae-4835-9c09-c1df15749866');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4ad4381b-d7f0-42d4-8279-595b3898c72d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4ad4381b-d7f0-42d4-8279-595b3898c72d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4ad4381b-d7f0-42d4-8279-595b3898c72d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbkqGaWOV_9B",
        "outputId": "39465965-e8f3-4c9f-8cb3-014c06189364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   review     50000 non-null  object\n",
            " 1   sentiment  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg5TQFrTWSlj",
        "outputId": "77076352-dbf2-49c5-ecc4-00ff9a054cbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive    25000\n",
              "negative    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df.sentiment.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "KKhdURvhW1rd",
        "outputId": "64ddc7f4-32ce-4ce9-82e7-483f1e2d8509"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df['review'][1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scstjDBcWcOl"
      },
      "outputs": [],
      "source": [
        "#### Removing HTML tags,punctuations,special characters etc using regular expressions.\n",
        "TAG_RE = re.compile(r'<[^>]+>') # match anything in the tag <...>\n",
        "\n",
        "def remove_tags(text):\n",
        "    #print(text)\n",
        "    return TAG_RE.sub('', text) # replace that tag with a null string\n",
        "\n",
        "def process_text(sen):\n",
        "    #print(sen)\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence) # look for any character except a toz or A to Z and replace with space\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence) # Look for one or more space with any a-z or a-Z letter followed by multiple space and replace with a space\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence) # finally check for continuous space and replace them with a single space\n",
        "\n",
        "    return sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_waFkd8tWsgO",
        "outputId": "54b2c012-1cef-4787-9174-76552e11df8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning took: 0.282 minutes\n"
          ]
        }
      ],
      "source": [
        "# clean text data\n",
        "start = time.time()\n",
        "for row in df.itertuples():\n",
        "    article = process_text(str(df.loc[row.Index,'review']))\n",
        "    df.loc[row.Index,'clean_review'] = article\n",
        "stop = time.time()\n",
        "print(f'Cleaning took: {round((stop-start)/60, 3)} minutes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "3MzYDOtPeJKE",
        "outputId": "b8068238-cad5-4ef8-c99a-c9eef1023bc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive   \n",
              "1  A wonderful little production. <br /><br />The...  positive   \n",
              "\n",
              "                                        clean_review  \n",
              "0  One of the other reviewers has mentioned that ...  \n",
              "1  A wonderful little production The filming tech...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f1d99b6-4435-4c7c-8e50-f6d93513cf77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>A wonderful little production The filming tech...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f1d99b6-4435-4c7c-8e50-f6d93513cf77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f1d99b6-4435-4c7c-8e50-f6d93513cf77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f1d99b6-4435-4c7c-8e50-f6d93513cf77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03dd6d0b-9a87-405d-8c27-32ed2861384b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03dd6d0b-9a87-405d-8c27-32ed2861384b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03dd6d0b-9a87-405d-8c27-32ed2861384b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "DQpd028ZWymS",
        "outputId": "4c64f6d8-92d2-4123-f281-8f05ec92bcd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mario Lewis of the Competitive Enterprise Institute has written a definitive 120-page point-by-point, line-by-line refutation of this mendacious film, which should be titled A CONVENIENT LIE. The website address where his debunking report, which is titled \"A SKEPTIC\\'S GUIDE TO AN INCONVENIENT TRUTH\" can be found at is :www.cei.org. A shorter 10-page version can be found at: www.cei.org/pdf/5539.pdf Once you read those demolitions, you\\'ll realize that alleged \"global warming\" is no more real or dangerous than the Y2K scare of 1999, which Gore also endorsed, as he did the pseudo-scientific film THE DAY AFTER TOMORROW, which was based on a book written by alleged UFO abductee Whitley Strieber. As James \"The Amazing\" Randi does to psychics, and Philip Klass does to UFOs, and Gerald Posner does to JFK conspir-idiocy theories, so does Mario Lewis does to Al Gore\\'s movie and the whole \"global warming\" scam.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df['review'][742]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "0wT8GvsReRHd",
        "outputId": "038f2193-3db5-4d19-d031-726d2fe2c65d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mario Lewis of the Competitive Enterprise Institute has written definitive page point by point line by line refutation of this mendacious film which should be titled CONVENIENT LIE The website address where his debunking report which is titled SKEPTIC GUIDE TO AN INCONVENIENT TRUTH can be found at is www cei org shorter page version can be found at www cei org pdf pdf Once you read those demolitions you ll realize that alleged global warming is no more real or dangerous than the scare of which Gore also endorsed as he did the pseudo scientific film THE DAY AFTER TOMORROW which was based on book written by alleged UFO abductee Whitley Strieber As James The Amazing Randi does to psychics and Philip Klass does to UFOs and Gerald Posner does to JFK conspir idiocy theories so does Mario Lewis does to Al Gore movie and the whole global warming scam '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df['clean_review'][742]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7ZtfQUwWyaU"
      },
      "outputs": [],
      "source": [
        "def remove_urls_emails(text):\n",
        "    # Remove URLs that start with 'http' or 'www' or emails\n",
        "    text = re.sub(r'\\bwww\\b', '', text)\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    return text\n",
        "\n",
        "# Apply the function to the 'sentiment' column\n",
        "df['clean_review'] = df['clean_review'].apply(remove_urls_emails)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_k0aS9iXBqh"
      },
      "outputs": [],
      "source": [
        "def get_wordnet_pos(pos_tag):\n",
        "    if pos_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif pos_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif pos_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif pos_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAUZYYeAXCir",
        "outputId": "fa026f82-39a5-43ae-c7e6-1696d8b442ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning took: 5.904 minutes\n"
          ]
        }
      ],
      "source": [
        "# These excluding words are important for capturing the negative sentiments.\n",
        "# Therefore, should not be taken out of the stopword list.\n",
        "def clean_review(text):\n",
        "    excluding = ['against', 'not', 'don', \"don't\",'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
        "             'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\",\n",
        "             'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\",\n",
        "             'needn', \"needn't\",'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren',\n",
        "             \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
        "    # lower text\n",
        "    text = text.lower()\n",
        "    # tokenize text and remove puncutation\n",
        "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
        "    # remove stop words\n",
        "    stop = stopwords.words('english')\n",
        "    #print(\"stop english\",stop)\n",
        "    # New stop word list\n",
        "    stop_words = [word for word in stop if word not in excluding]\n",
        "    #print(\"stop words\",stop_words)\n",
        "\n",
        "    text = [x for x in text if x not in stop_words]\n",
        "    #print(\"text words\",text)\n",
        "\n",
        "    text = [word.strip(string.punctuation) for word in text]\n",
        "\n",
        "    # remove empty tokens\n",
        "    text = [t for t in text if len(t) > 0]\n",
        "    # pos tag text\n",
        "    pos_tags = pos_tag(text)\n",
        "    # lemmatize text\n",
        "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
        "    # remove words with only one letter\n",
        "    text = [t for t in text if len(t) > 1]\n",
        "    # join all\n",
        "    text = \" \".join(text)\n",
        "    return(text)\n",
        "\n",
        "# clean text data\n",
        "start = time.time()\n",
        "df[\"clean_review\"] = df[\"clean_review\"].apply(lambda x: clean_review(x))\n",
        "stop = time.time()\n",
        "print(f'Cleaning took: {round((stop-start)/60, 3)} minutes')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XDXcsJYXNXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d578645b-5ae7-4fb6-da29-3dc92ac9ac27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment  \\\n",
              "0  One of the other reviewers has mentioned that ...  positive   \n",
              "1  A wonderful little production. <br /><br />The...  positive   \n",
              "2  I thought this was a wonderful way to spend ti...  positive   \n",
              "3  Basically there's a family where a little boy ...  negative   \n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
              "\n",
              "                                        clean_review  \n",
              "0  one reviewer mention watch oz episode hook rig...  \n",
              "1  wonderful little production film technique una...  \n",
              "2  think wonderful way spend time hot summer week...  \n",
              "3  basically family little boy jake think zombie ...  \n",
              "4  petter mattei love time money visually stunnin...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a4ee73b-fa4e-43af-8572-35bdc1dd4dbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewer mention watch oz episode hook rig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful little production film technique una...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>think wonderful way spend time hot summer week...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically family little boy jake think zombie ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei love time money visually stunnin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a4ee73b-fa4e-43af-8572-35bdc1dd4dbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a4ee73b-fa4e-43af-8572-35bdc1dd4dbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a4ee73b-fa4e-43af-8572-35bdc1dd4dbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e2839053-7a9c-46d3-8b05-c9d2456eac4f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2839053-7a9c-46d3-8b05-c9d2456eac4f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e2839053-7a9c-46d3-8b05-c9d2456eac4f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5Py0iLwXNUB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84852fef-dc53-4893-ebe1-de0907d3ec2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Series([], Name: review, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df[df[\"clean_review\"]==\"\"][\"review\"].value_counts() # No empty rows of clean_review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEwRtHf1XNRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25a6537-93b4-4d5e-f4be-d4f00bbd2a13"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "review          0\n",
              "sentiment       0\n",
              "clean_review    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E1Jr9g7XNOd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "58ccdcba-a5d1-4988-d266-769a3eb5eadf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment  \\\n",
              "49995  I thought this movie did a down right good job...  positive   \n",
              "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative   \n",
              "49997  I am a Catholic taught in parochial elementary...  negative   \n",
              "49998  I'm going to have to disagree with the previou...  negative   \n",
              "49999  No one expects the Star Trek movies to be high...  negative   \n",
              "\n",
              "                                            clean_review  \n",
              "49995  think movie right good job wasn creative origi...  \n",
              "49996  bad plot bad dialogue bad act idiotic direct a...  \n",
              "49997  catholic teach parochial elementary school nun...  \n",
              "49998  go disagree previous comment side maltin one s...  \n",
              "49999  one expect star trek movie high art fan expect...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98b53556-4551-455f-82e2-b1d5e384006c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>I thought this movie did a down right good job...</td>\n",
              "      <td>positive</td>\n",
              "      <td>think movie right good job wasn creative origi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
              "      <td>negative</td>\n",
              "      <td>bad plot bad dialogue bad act idiotic direct a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am a Catholic taught in parochial elementary...</td>\n",
              "      <td>negative</td>\n",
              "      <td>catholic teach parochial elementary school nun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>I'm going to have to disagree with the previou...</td>\n",
              "      <td>negative</td>\n",
              "      <td>go disagree previous comment side maltin one s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>No one expects the Star Trek movies to be high...</td>\n",
              "      <td>negative</td>\n",
              "      <td>one expect star trek movie high art fan expect...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98b53556-4551-455f-82e2-b1d5e384006c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98b53556-4551-455f-82e2-b1d5e384006c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98b53556-4551-455f-82e2-b1d5e384006c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fb6e2705-0dcb-4a70-98d5-8723094047c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fb6e2705-0dcb-4a70-98d5-8723094047c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fb6e2705-0dcb-4a70-98d5-8723094047c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uL6P_s3XNJp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "f1d102a5-c69c-442f-c6ba-0f283976dfad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  review sentiment  \\\n",
              "0      One of the other reviewers has mentioned that ...  positive   \n",
              "1      A wonderful little production. <br /><br />The...  positive   \n",
              "2      I thought this was a wonderful way to spend ti...  positive   \n",
              "3      Basically there's a family where a little boy ...  negative   \n",
              "4      Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
              "...                                                  ...       ...   \n",
              "49990  Lame, lame, lame!!! A 90-minute cringe-fest th...  negative   \n",
              "49991  Les Visiteurs, the first movie about the medie...  negative   \n",
              "49992  John Garfield plays a Marine who is blinded by...  positive   \n",
              "49993  Robert Colomb has two full-time jobs. He's kno...  negative   \n",
              "49994  This is your typical junk comedy.<br /><br />T...  negative   \n",
              "\n",
              "                                            clean_review  target  \n",
              "0      one reviewer mention watch oz episode hook rig...       1  \n",
              "1      wonderful little production film technique una...       1  \n",
              "2      think wonderful way spend time hot summer week...       1  \n",
              "3      basically family little boy jake think zombie ...       0  \n",
              "4      petter mattei love time money visually stunnin...       1  \n",
              "...                                                  ...     ...  \n",
              "49990  lame lame lame minute cringe fest minute long ...       0  \n",
              "49991  le visiteurs first movie medieval time travele...       0  \n",
              "49992  john garfield play marine blind grenade fight ...       1  \n",
              "49993  robert colomb two full time job know throughou...       0  \n",
              "49994  typical junk comedy almost laugh genuine momen...       0  \n",
              "\n",
              "[49995 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05b85084-d864-45b7-ad74-ecd18e52958a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>one reviewer mention watch oz episode hook rig...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "      <td>wonderful little production film technique una...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "      <td>think wonderful way spend time hot summer week...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>basically family little boy jake think zombie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "      <td>petter mattei love time money visually stunnin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49990</th>\n",
              "      <td>Lame, lame, lame!!! A 90-minute cringe-fest th...</td>\n",
              "      <td>negative</td>\n",
              "      <td>lame lame lame minute cringe fest minute long ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49991</th>\n",
              "      <td>Les Visiteurs, the first movie about the medie...</td>\n",
              "      <td>negative</td>\n",
              "      <td>le visiteurs first movie medieval time travele...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49992</th>\n",
              "      <td>John Garfield plays a Marine who is blinded by...</td>\n",
              "      <td>positive</td>\n",
              "      <td>john garfield play marine blind grenade fight ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49993</th>\n",
              "      <td>Robert Colomb has two full-time jobs. He's kno...</td>\n",
              "      <td>negative</td>\n",
              "      <td>robert colomb two full time job know throughou...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49994</th>\n",
              "      <td>This is your typical junk comedy.&lt;br /&gt;&lt;br /&gt;T...</td>\n",
              "      <td>negative</td>\n",
              "      <td>typical junk comedy almost laugh genuine momen...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>49995 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05b85084-d864-45b7-ad74-ecd18e52958a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05b85084-d864-45b7-ad74-ecd18e52958a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05b85084-d864-45b7-ad74-ecd18e52958a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1698008a-606e-4cfd-96fe-56712682ef5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1698008a-606e-4cfd-96fe-56712682ef5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1698008a-606e-4cfd-96fe-56712682ef5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df['target'] = np.where(df['sentiment']=='positive',1,0)\n",
        "df.head(-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving Cleaned File**"
      ],
      "metadata": {
        "id": "RlspnAi5LFMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/DeepLearning/HW/HW4/IMDB_cleaned.csv')"
      ],
      "metadata": {
        "id": "ZEIHPMUPupqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/DeepLearning/HW/HW4/IMDB_cleaned.csv')"
      ],
      "metadata": {
        "id": "rt5QjwbRGTcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Vocabulary,Train and use Doc2Vec Model with LSTM, GRU, Bi-RNN, Bi-LSTM, and Bi-GRU**"
      ],
      "metadata": {
        "id": "pCpaH5qqW23a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the text data for Doc2Vec Model\n",
        "tagged_data = [TaggedDocument(words=doc.split(), tags=[str(i)]) for i, doc in enumerate(df['clean_review'])]\n",
        "\n",
        "# Train Doc2Vec model\n",
        "doc2vec_model = Doc2Vec(vector_size=100, window=2, min_count=1, workers=4, epochs=10)\n",
        "doc2vec_model.build_vocab(tagged_data)\n",
        "doc2vec_model.train(tagged_data, total_examples=doc2vec_model.corpus_count, epochs=doc2vec_model.epochs)\n",
        "\n",
        "doc2vec_model.save(\"/content/drive/MyDrive/DeepLearning/HW/HW4/doc2vec_model\")\n"
      ],
      "metadata": {
        "id": "UXjD-d_zF8da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To check the vector of a document in the training data\n",
        "vector = doc2vec_model.dv['0']  # '0' is the tag of the document i.e. first row\n",
        "print(vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhSm1BfXL6CF",
        "outputId": "da249da6-6136-4574-ca57-aa8e9ab67bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.13464175 -0.25133464  0.10044955 -0.01193706 -0.7376709  -0.4771478\n",
            "  0.22209346  0.521544   -0.25811952 -0.05397695 -0.2764069  -0.5914641\n",
            " -0.04162106  0.12638962  0.0575166  -0.4638382   0.13832185 -0.3479379\n",
            " -0.05685578  0.11632762  0.03488091 -0.25225216  0.24196833  0.18280059\n",
            " -0.14919634 -0.27191666 -0.2348101   0.42264676 -0.09047851 -0.16482033\n",
            "  0.3396192  -0.06394333  0.4556848   0.223492    0.15642081 -0.45630544\n",
            "  0.11386944 -0.09053209  0.31524456  0.38856864  0.10267985  0.00438661\n",
            "  0.5143395   0.1307315   0.31057185 -0.9038223  -0.21882269  0.07157907\n",
            " -0.18373077  0.19084336  0.1984848   0.18817134  0.15500209  0.3257857\n",
            " -0.3319201   0.29711214  0.11135387  0.05300928 -0.09766208  0.0232433\n",
            "  0.09195484 -0.18509454  0.2931629   0.1178014   0.13873847 -0.1567614\n",
            "  0.23357879  0.1361525   0.5716606  -0.014956    0.29834306 -0.1365012\n",
            "  0.10821853 -0.26629287  0.19608444 -0.14297348  0.19144753 -0.62094706\n",
            " -0.6112086   0.12768774 -0.04377558  0.18919249 -0.01383282  0.4509022\n",
            " -0.7016792  -0.30344704 -0.01666065 -0.3583599   0.5325076   0.24261113\n",
            " -0.35718045  0.38149372  0.02901746 -0.20106003  0.13714617  0.14998126\n",
            "  0.32590297 -0.08639991  0.06439871  0.28952157]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results =[]"
      ],
      "metadata": {
        "id": "Xx5kvEH1WdrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc2vec_model = Doc2Vec.load(\"/content/drive/MyDrive/DeepLearning/HW/HW4/doc2vec_model\")\n",
        "\n",
        "# Get document embeddings\n",
        "doc_embeddings = np.array([doc2vec_model.infer_vector(doc.split()) for doc in df['clean_review']])\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(doc_embeddings, df['target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Reshape the input data for all bidirectional models\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "models = [\n",
        "    (SimpleRNN(128), \"RNN\"),\n",
        "    (LSTM(128), \"LSTM\"),\n",
        "    (GRU(128), \"GRU\"),\n",
        "    (Bidirectional(SimpleRNN(128, return_sequences=True), input_shape=(1, doc_embeddings.shape[1])), \"Bi-RNN\"),\n",
        "    (Bidirectional(LSTM(128, return_sequences=True), input_shape=(1, doc_embeddings.shape[1])), \"Bi-LSTM\"),\n",
        "    (Bidirectional(GRU(128, return_sequences=True), input_shape=(1, doc_embeddings.shape[1])), \"Bi-GRU\")\n",
        "]\n",
        "\n",
        "# Train and evaluate each model\n",
        "for model, model_name in models:\n",
        "    print(f\"Training {model_name}...\")\n",
        "\n",
        "    # Build model\n",
        "    model_sequence = Sequential()\n",
        "    model_sequence.add(model)\n",
        "    model_sequence.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile model\n",
        "    model_sequence.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train model\n",
        "    model_sequence.fit(X_train_reshaped, y_train, epochs=20, batch_size=32, validation_split=0.2, verbose=2)\n",
        "\n",
        "    y_pred = model_sequence.predict(X_test_reshaped)\n",
        "\n",
        "    # Convert probabilities to class labels\n",
        "    y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    # Ensure y_test is a 1D array of binary values\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    # Ensure y_pred_labels is a 1D array of binary values\n",
        "    y_pred_labels = y_pred_labels.flatten()\n",
        "\n",
        "    # Print classification report and confusion matrix\n",
        "    print(f\"Classification Report for {model_name} with Doc2Vec :\")\n",
        "    print(classification_report(y_test, y_pred_labels))\n",
        "\n",
        "    # Print confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test, y_pred_labels)\n",
        "    print(f\"Confusion Matrix for {model_name} with Doc2Vec :\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Calculate accuracy using confusion matrix values\n",
        "    accuracy_from_conf_matrix = (conf_matrix[0, 0] + conf_matrix[1, 1]) / np.sum(conf_matrix)\n",
        "    #print(f\"Accuracy calculated from confusion matrix: {accuracy_from_conf_matrix * 100:.2f}%\")\n",
        "    print(f'{model_name} with Doc2Vec embedding has an Accuracy of: {accuracy_from_conf_matrix * 100:.2f}%')\n",
        "\n",
        "    results.append({'Embedding' : 'Doc2Vec', 'Model': model_name, 'Accuracy': accuracy_from_conf_matrix * 100})\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtzhIm01STro",
        "outputId": "6e0863af-c24d-44fa-eb39-a994b08dc8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training RNN...\n",
            "Epoch 1/20\n",
            "1000/1000 - 4s - loss: 0.3735 - accuracy: 0.8365 - val_loss: 0.3517 - val_accuracy: 0.8564 - 4s/epoch - 4ms/step\n",
            "Epoch 2/20\n",
            "1000/1000 - 3s - loss: 0.3601 - accuracy: 0.8441 - val_loss: 0.3495 - val_accuracy: 0.8549 - 3s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1000/1000 - 3s - loss: 0.3578 - accuracy: 0.8447 - val_loss: 0.3492 - val_accuracy: 0.8569 - 3s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1000/1000 - 3s - loss: 0.3556 - accuracy: 0.8453 - val_loss: 0.3476 - val_accuracy: 0.8555 - 3s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1000/1000 - 3s - loss: 0.3528 - accuracy: 0.8462 - val_loss: 0.3454 - val_accuracy: 0.8574 - 3s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1000/1000 - 3s - loss: 0.3499 - accuracy: 0.8471 - val_loss: 0.3419 - val_accuracy: 0.8602 - 3s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "1000/1000 - 3s - loss: 0.3469 - accuracy: 0.8509 - val_loss: 0.3425 - val_accuracy: 0.8574 - 3s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "1000/1000 - 3s - loss: 0.3436 - accuracy: 0.8518 - val_loss: 0.3398 - val_accuracy: 0.8577 - 3s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "1000/1000 - 3s - loss: 0.3409 - accuracy: 0.8508 - val_loss: 0.3392 - val_accuracy: 0.8586 - 3s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "1000/1000 - 3s - loss: 0.3374 - accuracy: 0.8524 - val_loss: 0.3413 - val_accuracy: 0.8564 - 3s/epoch - 3ms/step\n",
            "Epoch 11/20\n",
            "1000/1000 - 3s - loss: 0.3340 - accuracy: 0.8546 - val_loss: 0.3373 - val_accuracy: 0.8590 - 3s/epoch - 3ms/step\n",
            "Epoch 12/20\n",
            "1000/1000 - 3s - loss: 0.3312 - accuracy: 0.8576 - val_loss: 0.3373 - val_accuracy: 0.8589 - 3s/epoch - 3ms/step\n",
            "Epoch 13/20\n",
            "1000/1000 - 3s - loss: 0.3268 - accuracy: 0.8583 - val_loss: 0.3385 - val_accuracy: 0.8566 - 3s/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "1000/1000 - 3s - loss: 0.3232 - accuracy: 0.8609 - val_loss: 0.3399 - val_accuracy: 0.8561 - 3s/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "1000/1000 - 3s - loss: 0.3200 - accuracy: 0.8614 - val_loss: 0.3362 - val_accuracy: 0.8589 - 3s/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "1000/1000 - 3s - loss: 0.3155 - accuracy: 0.8641 - val_loss: 0.3386 - val_accuracy: 0.8572 - 3s/epoch - 3ms/step\n",
            "Epoch 17/20\n",
            "1000/1000 - 3s - loss: 0.3115 - accuracy: 0.8665 - val_loss: 0.3371 - val_accuracy: 0.8556 - 3s/epoch - 3ms/step\n",
            "Epoch 18/20\n",
            "1000/1000 - 3s - loss: 0.3067 - accuracy: 0.8680 - val_loss: 0.3373 - val_accuracy: 0.8580 - 3s/epoch - 3ms/step\n",
            "Epoch 19/20\n",
            "1000/1000 - 3s - loss: 0.3020 - accuracy: 0.8712 - val_loss: 0.3405 - val_accuracy: 0.8570 - 3s/epoch - 3ms/step\n",
            "Epoch 20/20\n",
            "1000/1000 - 3s - loss: 0.2976 - accuracy: 0.8738 - val_loss: 0.3410 - val_accuracy: 0.8545 - 3s/epoch - 3ms/step\n",
            "313/313 [==============================] - 1s 1ms/step\n",
            "Classification Report for RNN with Doc2Vec :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.85      4961\n",
            "           1       0.85      0.84      0.85      5039\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n",
            "Confusion Matrix for RNN with Doc2Vec :\n",
            "[[4219  742]\n",
            " [ 801 4238]]\n",
            "RNN with Doc2Vec embedding has an Accuracy of: 84.57%\n",
            "Training LSTM...\n",
            "Epoch 1/20\n",
            "1000/1000 - 5s - loss: 0.3784 - accuracy: 0.8382 - val_loss: 0.3447 - val_accuracy: 0.8577 - 5s/epoch - 5ms/step\n",
            "Epoch 2/20\n",
            "1000/1000 - 3s - loss: 0.3488 - accuracy: 0.8479 - val_loss: 0.3399 - val_accuracy: 0.8595 - 3s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1000/1000 - 3s - loss: 0.3403 - accuracy: 0.8518 - val_loss: 0.3394 - val_accuracy: 0.8600 - 3s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1000/1000 - 3s - loss: 0.3329 - accuracy: 0.8545 - val_loss: 0.3372 - val_accuracy: 0.8610 - 3s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1000/1000 - 3s - loss: 0.3245 - accuracy: 0.8589 - val_loss: 0.3377 - val_accuracy: 0.8609 - 3s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1000/1000 - 3s - loss: 0.3166 - accuracy: 0.8617 - val_loss: 0.3360 - val_accuracy: 0.8595 - 3s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "1000/1000 - 3s - loss: 0.3083 - accuracy: 0.8668 - val_loss: 0.3400 - val_accuracy: 0.8584 - 3s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "1000/1000 - 3s - loss: 0.2998 - accuracy: 0.8712 - val_loss: 0.3429 - val_accuracy: 0.8565 - 3s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "1000/1000 - 3s - loss: 0.2908 - accuracy: 0.8758 - val_loss: 0.3460 - val_accuracy: 0.8547 - 3s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "1000/1000 - 3s - loss: 0.2818 - accuracy: 0.8808 - val_loss: 0.3519 - val_accuracy: 0.8537 - 3s/epoch - 3ms/step\n",
            "Epoch 11/20\n",
            "1000/1000 - 3s - loss: 0.2727 - accuracy: 0.8848 - val_loss: 0.3551 - val_accuracy: 0.8526 - 3s/epoch - 3ms/step\n",
            "Epoch 12/20\n",
            "1000/1000 - 3s - loss: 0.2634 - accuracy: 0.8908 - val_loss: 0.3586 - val_accuracy: 0.8491 - 3s/epoch - 3ms/step\n",
            "Epoch 13/20\n",
            "1000/1000 - 3s - loss: 0.2540 - accuracy: 0.8945 - val_loss: 0.3723 - val_accuracy: 0.8471 - 3s/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "1000/1000 - 3s - loss: 0.2455 - accuracy: 0.8985 - val_loss: 0.3750 - val_accuracy: 0.8464 - 3s/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "1000/1000 - 3s - loss: 0.2362 - accuracy: 0.9034 - val_loss: 0.3817 - val_accuracy: 0.8450 - 3s/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "1000/1000 - 3s - loss: 0.2263 - accuracy: 0.9083 - val_loss: 0.3893 - val_accuracy: 0.8455 - 3s/epoch - 3ms/step\n",
            "Epoch 17/20\n",
            "1000/1000 - 3s - loss: 0.2175 - accuracy: 0.9123 - val_loss: 0.3975 - val_accuracy: 0.8439 - 3s/epoch - 3ms/step\n",
            "Epoch 18/20\n",
            "1000/1000 - 3s - loss: 0.2084 - accuracy: 0.9172 - val_loss: 0.4053 - val_accuracy: 0.8396 - 3s/epoch - 3ms/step\n",
            "Epoch 19/20\n",
            "1000/1000 - 3s - loss: 0.1994 - accuracy: 0.9206 - val_loss: 0.4131 - val_accuracy: 0.8371 - 3s/epoch - 3ms/step\n",
            "Epoch 20/20\n",
            "1000/1000 - 3s - loss: 0.1895 - accuracy: 0.9262 - val_loss: 0.4217 - val_accuracy: 0.8351 - 3s/epoch - 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Classification Report for LSTM with Doc2Vec :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84      4961\n",
            "           1       0.85      0.84      0.84      5039\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "Confusion Matrix for LSTM with Doc2Vec :\n",
            "[[4198  763]\n",
            " [ 816 4223]]\n",
            "LSTM with Doc2Vec embedding has an Accuracy of: 84.21%\n",
            "Training GRU...\n",
            "Epoch 1/20\n",
            "1000/1000 - 5s - loss: 0.3745 - accuracy: 0.8383 - val_loss: 0.3502 - val_accuracy: 0.8560 - 5s/epoch - 5ms/step\n",
            "Epoch 2/20\n",
            "1000/1000 - 3s - loss: 0.3519 - accuracy: 0.8472 - val_loss: 0.3434 - val_accuracy: 0.8593 - 3s/epoch - 3ms/step\n",
            "Epoch 3/20\n",
            "1000/1000 - 3s - loss: 0.3443 - accuracy: 0.8507 - val_loss: 0.3399 - val_accuracy: 0.8593 - 3s/epoch - 3ms/step\n",
            "Epoch 4/20\n",
            "1000/1000 - 3s - loss: 0.3374 - accuracy: 0.8518 - val_loss: 0.3400 - val_accuracy: 0.8599 - 3s/epoch - 3ms/step\n",
            "Epoch 5/20\n",
            "1000/1000 - 3s - loss: 0.3308 - accuracy: 0.8550 - val_loss: 0.3386 - val_accuracy: 0.8611 - 3s/epoch - 3ms/step\n",
            "Epoch 6/20\n",
            "1000/1000 - 3s - loss: 0.3233 - accuracy: 0.8598 - val_loss: 0.3383 - val_accuracy: 0.8611 - 3s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "1000/1000 - 3s - loss: 0.3170 - accuracy: 0.8628 - val_loss: 0.3402 - val_accuracy: 0.8580 - 3s/epoch - 3ms/step\n",
            "Epoch 8/20\n",
            "1000/1000 - 3s - loss: 0.3096 - accuracy: 0.8657 - val_loss: 0.3415 - val_accuracy: 0.8564 - 3s/epoch - 3ms/step\n",
            "Epoch 9/20\n",
            "1000/1000 - 3s - loss: 0.3018 - accuracy: 0.8697 - val_loss: 0.3443 - val_accuracy: 0.8562 - 3s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "1000/1000 - 3s - loss: 0.2944 - accuracy: 0.8746 - val_loss: 0.3503 - val_accuracy: 0.8528 - 3s/epoch - 3ms/step\n",
            "Epoch 11/20\n",
            "1000/1000 - 3s - loss: 0.2868 - accuracy: 0.8782 - val_loss: 0.3509 - val_accuracy: 0.8553 - 3s/epoch - 3ms/step\n",
            "Epoch 12/20\n",
            "1000/1000 - 3s - loss: 0.2784 - accuracy: 0.8839 - val_loss: 0.3563 - val_accuracy: 0.8521 - 3s/epoch - 3ms/step\n",
            "Epoch 13/20\n",
            "1000/1000 - 3s - loss: 0.2713 - accuracy: 0.8866 - val_loss: 0.3618 - val_accuracy: 0.8510 - 3s/epoch - 3ms/step\n",
            "Epoch 14/20\n",
            "1000/1000 - 3s - loss: 0.2637 - accuracy: 0.8893 - val_loss: 0.3645 - val_accuracy: 0.8479 - 3s/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "1000/1000 - 3s - loss: 0.2558 - accuracy: 0.8947 - val_loss: 0.3729 - val_accuracy: 0.8460 - 3s/epoch - 3ms/step\n",
            "Epoch 16/20\n",
            "1000/1000 - 3s - loss: 0.2484 - accuracy: 0.8981 - val_loss: 0.3781 - val_accuracy: 0.8471 - 3s/epoch - 3ms/step\n",
            "Epoch 17/20\n",
            "1000/1000 - 3s - loss: 0.2404 - accuracy: 0.9018 - val_loss: 0.3920 - val_accuracy: 0.8436 - 3s/epoch - 3ms/step\n",
            "Epoch 18/20\n",
            "1000/1000 - 3s - loss: 0.2333 - accuracy: 0.9058 - val_loss: 0.3908 - val_accuracy: 0.8440 - 3s/epoch - 3ms/step\n",
            "Epoch 19/20\n",
            "1000/1000 - 3s - loss: 0.2254 - accuracy: 0.9107 - val_loss: 0.4043 - val_accuracy: 0.8399 - 3s/epoch - 3ms/step\n",
            "Epoch 20/20\n",
            "1000/1000 - 3s - loss: 0.2177 - accuracy: 0.9133 - val_loss: 0.4099 - val_accuracy: 0.8409 - 3s/epoch - 3ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Classification Report for GRU with Doc2Vec :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.82      0.83      4961\n",
            "           1       0.83      0.85      0.84      5039\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "Confusion Matrix for GRU with Doc2Vec :\n",
            "[[4057  904]\n",
            " [ 740 4299]]\n",
            "GRU with Doc2Vec embedding has an Accuracy of: 83.56%\n",
            "Training Bi-RNN...\n",
            "Epoch 1/20\n",
            "1000/1000 - 6s - loss: 0.3729 - accuracy: 0.8375 - val_loss: 0.3529 - val_accuracy: 0.8556 - 6s/epoch - 6ms/step\n",
            "Epoch 2/20\n",
            "1000/1000 - 4s - loss: 0.3615 - accuracy: 0.8436 - val_loss: 0.3508 - val_accuracy: 0.8546 - 4s/epoch - 4ms/step\n",
            "Epoch 3/20\n",
            "1000/1000 - 4s - loss: 0.3594 - accuracy: 0.8438 - val_loss: 0.3485 - val_accuracy: 0.8570 - 4s/epoch - 4ms/step\n",
            "Epoch 4/20\n",
            "1000/1000 - 4s - loss: 0.3559 - accuracy: 0.8453 - val_loss: 0.3464 - val_accuracy: 0.8609 - 4s/epoch - 4ms/step\n",
            "Epoch 5/20\n",
            "1000/1000 - 4s - loss: 0.3542 - accuracy: 0.8467 - val_loss: 0.3438 - val_accuracy: 0.8593 - 4s/epoch - 4ms/step\n",
            "Epoch 6/20\n",
            "1000/1000 - 3s - loss: 0.3514 - accuracy: 0.8455 - val_loss: 0.3474 - val_accuracy: 0.8566 - 3s/epoch - 3ms/step\n",
            "Epoch 7/20\n",
            "1000/1000 - 4s - loss: 0.3485 - accuracy: 0.8476 - val_loss: 0.3431 - val_accuracy: 0.8580 - 4s/epoch - 4ms/step\n",
            "Epoch 8/20\n",
            "1000/1000 - 4s - loss: 0.3449 - accuracy: 0.8497 - val_loss: 0.3429 - val_accuracy: 0.8584 - 4s/epoch - 4ms/step\n",
            "Epoch 9/20\n",
            "1000/1000 - 3s - loss: 0.3414 - accuracy: 0.8510 - val_loss: 0.3385 - val_accuracy: 0.8609 - 3s/epoch - 3ms/step\n",
            "Epoch 10/20\n",
            "1000/1000 - 4s - loss: 0.3378 - accuracy: 0.8517 - val_loss: 0.3382 - val_accuracy: 0.8586 - 4s/epoch - 4ms/step\n",
            "Epoch 11/20\n",
            "1000/1000 - 4s - loss: 0.3335 - accuracy: 0.8553 - val_loss: 0.3389 - val_accuracy: 0.8572 - 4s/epoch - 4ms/step\n",
            "Epoch 12/20\n",
            "1000/1000 - 4s - loss: 0.3300 - accuracy: 0.8559 - val_loss: 0.3359 - val_accuracy: 0.8595 - 4s/epoch - 4ms/step\n",
            "Epoch 13/20\n",
            "1000/1000 - 4s - loss: 0.3253 - accuracy: 0.8588 - val_loss: 0.3370 - val_accuracy: 0.8589 - 4s/epoch - 4ms/step\n",
            "Epoch 14/20\n",
            "1000/1000 - 3s - loss: 0.3205 - accuracy: 0.8612 - val_loss: 0.3398 - val_accuracy: 0.8575 - 3s/epoch - 3ms/step\n",
            "Epoch 15/20\n",
            "1000/1000 - 4s - loss: 0.3166 - accuracy: 0.8632 - val_loss: 0.3364 - val_accuracy: 0.8579 - 4s/epoch - 4ms/step\n",
            "Epoch 16/20\n",
            "1000/1000 - 4s - loss: 0.3111 - accuracy: 0.8660 - val_loss: 0.3371 - val_accuracy: 0.8570 - 4s/epoch - 4ms/step\n",
            "Epoch 17/20\n",
            "1000/1000 - 3s - loss: 0.3062 - accuracy: 0.8674 - val_loss: 0.3424 - val_accuracy: 0.8569 - 3s/epoch - 3ms/step\n",
            "Epoch 18/20\n",
            "1000/1000 - 3s - loss: 0.3013 - accuracy: 0.8713 - val_loss: 0.3433 - val_accuracy: 0.8579 - 3s/epoch - 3ms/step\n",
            "Epoch 19/20\n",
            "1000/1000 - 4s - loss: 0.2958 - accuracy: 0.8730 - val_loss: 0.3396 - val_accuracy: 0.8580 - 4s/epoch - 4ms/step\n",
            "Epoch 20/20\n",
            "1000/1000 - 4s - loss: 0.2905 - accuracy: 0.8760 - val_loss: 0.3418 - val_accuracy: 0.8549 - 4s/epoch - 4ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Classification Report for Bi-RNN with Doc2Vec :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.85      0.84      4961\n",
            "           1       0.85      0.84      0.85      5039\n",
            "\n",
            "    accuracy                           0.84     10000\n",
            "   macro avg       0.84      0.84      0.84     10000\n",
            "weighted avg       0.84      0.84      0.84     10000\n",
            "\n",
            "Confusion Matrix for Bi-RNN with Doc2Vec :\n",
            "[[4210  751]\n",
            " [ 803 4236]]\n",
            "Bi-RNN with Doc2Vec embedding has an Accuracy of: 84.46%\n",
            "Training Bi-LSTM...\n",
            "Epoch 1/20\n",
            "1000/1000 - 9s - loss: 0.3735 - accuracy: 0.8396 - val_loss: 0.3469 - val_accuracy: 0.8554 - 9s/epoch - 9ms/step\n",
            "Epoch 2/20\n",
            "1000/1000 - 4s - loss: 0.3476 - accuracy: 0.8475 - val_loss: 0.3403 - val_accuracy: 0.8597 - 4s/epoch - 4ms/step\n",
            "Epoch 3/20\n",
            "1000/1000 - 4s - loss: 0.3385 - accuracy: 0.8525 - val_loss: 0.3384 - val_accuracy: 0.8591 - 4s/epoch - 4ms/step\n",
            "Epoch 4/20\n",
            "1000/1000 - 4s - loss: 0.3297 - accuracy: 0.8570 - val_loss: 0.3373 - val_accuracy: 0.8605 - 4s/epoch - 4ms/step\n",
            "Epoch 5/20\n",
            "1000/1000 - 4s - loss: 0.3208 - accuracy: 0.8615 - val_loss: 0.3404 - val_accuracy: 0.8604 - 4s/epoch - 4ms/step\n",
            "Epoch 6/20\n",
            "1000/1000 - 4s - loss: 0.3116 - accuracy: 0.8647 - val_loss: 0.3410 - val_accuracy: 0.8594 - 4s/epoch - 4ms/step\n",
            "Epoch 7/20\n",
            "1000/1000 - 4s - loss: 0.3011 - accuracy: 0.8703 - val_loss: 0.3450 - val_accuracy: 0.8556 - 4s/epoch - 4ms/step\n",
            "Epoch 8/20\n",
            "1000/1000 - 4s - loss: 0.2911 - accuracy: 0.8755 - val_loss: 0.3503 - val_accuracy: 0.8535 - 4s/epoch - 4ms/step\n",
            "Epoch 9/20\n",
            "1000/1000 - 4s - loss: 0.2813 - accuracy: 0.8812 - val_loss: 0.3582 - val_accuracy: 0.8529 - 4s/epoch - 4ms/step\n",
            "Epoch 10/20\n",
            "1000/1000 - 4s - loss: 0.2705 - accuracy: 0.8862 - val_loss: 0.3649 - val_accuracy: 0.8479 - 4s/epoch - 4ms/step\n",
            "Epoch 11/20\n",
            "1000/1000 - 4s - loss: 0.2599 - accuracy: 0.8924 - val_loss: 0.3684 - val_accuracy: 0.8440 - 4s/epoch - 4ms/step\n",
            "Epoch 12/20\n",
            "1000/1000 - 4s - loss: 0.2480 - accuracy: 0.8979 - val_loss: 0.3792 - val_accuracy: 0.8464 - 4s/epoch - 4ms/step\n",
            "Epoch 13/20\n",
            "1000/1000 - 4s - loss: 0.2373 - accuracy: 0.9030 - val_loss: 0.3857 - val_accuracy: 0.8475 - 4s/epoch - 4ms/step\n",
            "Epoch 14/20\n",
            "1000/1000 - 4s - loss: 0.2257 - accuracy: 0.9094 - val_loss: 0.4012 - val_accuracy: 0.8407 - 4s/epoch - 4ms/step\n",
            "Epoch 15/20\n",
            "1000/1000 - 4s - loss: 0.2147 - accuracy: 0.9154 - val_loss: 0.4068 - val_accuracy: 0.8411 - 4s/epoch - 4ms/step\n",
            "Epoch 16/20\n",
            "1000/1000 - 4s - loss: 0.2038 - accuracy: 0.9197 - val_loss: 0.4182 - val_accuracy: 0.8371 - 4s/epoch - 4ms/step\n",
            "Epoch 17/20\n",
            "1000/1000 - 4s - loss: 0.1923 - accuracy: 0.9274 - val_loss: 0.4283 - val_accuracy: 0.8384 - 4s/epoch - 4ms/step\n",
            "Epoch 18/20\n",
            "1000/1000 - 4s - loss: 0.1817 - accuracy: 0.9298 - val_loss: 0.4447 - val_accuracy: 0.8370 - 4s/epoch - 4ms/step\n",
            "Epoch 19/20\n",
            "1000/1000 - 4s - loss: 0.1703 - accuracy: 0.9350 - val_loss: 0.4534 - val_accuracy: 0.8361 - 4s/epoch - 4ms/step\n",
            "Epoch 20/20\n",
            "1000/1000 - 4s - loss: 0.1600 - accuracy: 0.9405 - val_loss: 0.4667 - val_accuracy: 0.8324 - 4s/epoch - 4ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Classification Report for Bi-LSTM with Doc2Vec :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.84      0.83      4961\n",
            "           1       0.84      0.82      0.83      5039\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "Confusion Matrix for Bi-LSTM with Doc2Vec :\n",
            "[[4179  782]\n",
            " [ 898 4141]]\n",
            "Bi-LSTM with Doc2Vec embedding has an Accuracy of: 83.20%\n",
            "Training Bi-GRU...\n",
            "Epoch 1/20\n",
            "1000/1000 - 7s - loss: 0.3723 - accuracy: 0.8405 - val_loss: 0.3459 - val_accuracy: 0.8577 - 7s/epoch - 7ms/step\n",
            "Epoch 2/20\n",
            "1000/1000 - 4s - loss: 0.3515 - accuracy: 0.8474 - val_loss: 0.3439 - val_accuracy: 0.8597 - 4s/epoch - 4ms/step\n",
            "Epoch 3/20\n",
            "1000/1000 - 4s - loss: 0.3438 - accuracy: 0.8505 - val_loss: 0.3402 - val_accuracy: 0.8593 - 4s/epoch - 4ms/step\n",
            "Epoch 4/20\n",
            "1000/1000 - 4s - loss: 0.3361 - accuracy: 0.8534 - val_loss: 0.3390 - val_accuracy: 0.8604 - 4s/epoch - 4ms/step\n",
            "Epoch 5/20\n",
            "1000/1000 - 4s - loss: 0.3284 - accuracy: 0.8579 - val_loss: 0.3380 - val_accuracy: 0.8624 - 4s/epoch - 4ms/step\n",
            "Epoch 6/20\n",
            "1000/1000 - 4s - loss: 0.3208 - accuracy: 0.8602 - val_loss: 0.3422 - val_accuracy: 0.8597 - 4s/epoch - 4ms/step\n",
            "Epoch 7/20\n",
            "1000/1000 - 4s - loss: 0.3135 - accuracy: 0.8648 - val_loss: 0.3408 - val_accuracy: 0.8581 - 4s/epoch - 4ms/step\n",
            "Epoch 8/20\n",
            "1000/1000 - 4s - loss: 0.3040 - accuracy: 0.8691 - val_loss: 0.3448 - val_accuracy: 0.8556 - 4s/epoch - 4ms/step\n",
            "Epoch 9/20\n",
            "1000/1000 - 4s - loss: 0.2959 - accuracy: 0.8726 - val_loss: 0.3497 - val_accuracy: 0.8549 - 4s/epoch - 4ms/step\n",
            "Epoch 10/20\n",
            "1000/1000 - 4s - loss: 0.2877 - accuracy: 0.8786 - val_loss: 0.3533 - val_accuracy: 0.8522 - 4s/epoch - 4ms/step\n",
            "Epoch 11/20\n",
            "1000/1000 - 4s - loss: 0.2787 - accuracy: 0.8827 - val_loss: 0.3593 - val_accuracy: 0.8509 - 4s/epoch - 4ms/step\n",
            "Epoch 12/20\n",
            "1000/1000 - 4s - loss: 0.2700 - accuracy: 0.8870 - val_loss: 0.3650 - val_accuracy: 0.8484 - 4s/epoch - 4ms/step\n",
            "Epoch 13/20\n",
            "1000/1000 - 4s - loss: 0.2618 - accuracy: 0.8913 - val_loss: 0.3736 - val_accuracy: 0.8512 - 4s/epoch - 4ms/step\n",
            "Epoch 14/20\n",
            "1000/1000 - 4s - loss: 0.2533 - accuracy: 0.8967 - val_loss: 0.3778 - val_accuracy: 0.8459 - 4s/epoch - 4ms/step\n",
            "Epoch 15/20\n",
            "1000/1000 - 4s - loss: 0.2447 - accuracy: 0.8999 - val_loss: 0.3887 - val_accuracy: 0.8453 - 4s/epoch - 4ms/step\n",
            "Epoch 16/20\n",
            "1000/1000 - 4s - loss: 0.2353 - accuracy: 0.9042 - val_loss: 0.3988 - val_accuracy: 0.8388 - 4s/epoch - 4ms/step\n",
            "Epoch 17/20\n",
            "1000/1000 - 4s - loss: 0.2256 - accuracy: 0.9087 - val_loss: 0.4062 - val_accuracy: 0.8424 - 4s/epoch - 4ms/step\n",
            "Epoch 18/20\n",
            "1000/1000 - 4s - loss: 0.2168 - accuracy: 0.9134 - val_loss: 0.4118 - val_accuracy: 0.8394 - 4s/epoch - 4ms/step\n",
            "Epoch 19/20\n",
            "1000/1000 - 4s - loss: 0.2072 - accuracy: 0.9179 - val_loss: 0.4230 - val_accuracy: 0.8405 - 4s/epoch - 4ms/step\n",
            "Epoch 20/20\n",
            "1000/1000 - 4s - loss: 0.1983 - accuracy: 0.9215 - val_loss: 0.4335 - val_accuracy: 0.8346 - 4s/epoch - 4ms/step\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "Classification Report for Bi-GRU with Doc2Vec :\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.82      0.83      4961\n",
            "           1       0.83      0.85      0.84      5039\n",
            "\n",
            "    accuracy                           0.83     10000\n",
            "   macro avg       0.83      0.83      0.83     10000\n",
            "weighted avg       0.83      0.83      0.83     10000\n",
            "\n",
            "Confusion Matrix for Bi-GRU with Doc2Vec :\n",
            "[[4067  894]\n",
            " [ 763 4276]]\n",
            "Bi-GRU with Doc2Vec embedding has an Accuracy of: 83.43%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec, Glove, Fasttext**"
      ],
      "metadata": {
        "id": "W_WHdYiJUGhe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRXA5tVhddVd"
      },
      "outputs": [],
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_review'], df['target'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KddGYArdb28",
        "outputId": "21f612dd-4627-4d37-8ceb-72137c149f45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((40000,), (10000,), (40000,), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXmf3wy_wl9r",
        "outputId": "3b135b94-42a6-492c-d6f0-9d069c8d04e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39087    keep ask many fight scream match swear general...\n",
              "30893    not watch entire movie could not watch entire ...\n",
              "45278    touch love story reminiscent mood love draw he...\n",
              "16398    latter day fulci schlocker totally abysmal con...\n",
              "13653    first firmly believe norwegian movie continual...\n",
              "                               ...                        \n",
              "11284    shadow magic recapture joy amazement first mov...\n",
              "44732    find movie quite enjoyable fairly entertain go...\n",
              "38158    avoid one terrible movie excite pointless murd...\n",
              "860      production quite surprise absolutely love obsc...\n",
              "15795    decent movie although little bit short time pa...\n",
              "Name: clean_review, Length: 40000, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0e8scQwpEuy",
        "outputId": "855579db-2f11-41a5-e023-8ffa747bafc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('one reviewer mention watch oz episode hook right exactly happen first thing strike oz brutality unflinching scene violence set right word go trust not show faint hearted timid show pull punch regard drug sex violence hardcore classic use word call oz nickname give oswald maximum security state penitentary focus mainly emerald city experimental section prison cell glass front face inwards privacy not high agenda em city home many aryan muslim gangstas latinos christian italian irish scuffle death stare dodgy dealing shady agreement never far away would say main appeal show due fact go show wouldn dare forget pretty picture paint mainstream audience forget charm forget romance oz doesn mess around first episode ever saw struck nasty surreal couldn say ready watch developed taste oz get accustomed high level graphic violence not violence injustice crook guard sell nickel inmate kill order get away well mannered middle class inmate turn prison bitch due lack street skill prison experience watch oz may become comfortable uncomfortable view thats get touch darker side',\n",
              " 1)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "X_train[0], y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DTLD9_aPlroe",
        "outputId": "22f15f5f-f3b7-49aa-d4ac-e9af73611114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum number of words: 82241\n"
          ]
        }
      ],
      "source": [
        "# Calculate the maximum number of words dynamically\n",
        "max_words = len(set(\" \".join(X_train).split()))\n",
        "print(\"Maximum number of words:\", max_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iD6JLe1IpPmW"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "X_train_sequence = tokenizer.texts_to_sequences(X_train)\n",
        "X_test_sequence = tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "rN52wqcxwl9s",
        "outputId": "16a26c8e-5a92-4c18-abc2-33ad295c2fb6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming X_train is a list of sequences\n",
        "sequence_lengths = [len(seq) for seq in X_train]\n",
        "\n",
        "# Plot a histogram of sequence lengths\n",
        "plt.hist(sequence_lengths, bins=50,log=True)\n",
        "plt.xlabel('Sequence Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Distribution of Sequence Lengths')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The distribution of sequence I checked to see how much max length should I keep to keep the maximum information intact. I tried with 8000, 4000, and 2000 but it was taking way too long. So, going with 400 because it has highest frequency and also\n",
        "for efficiency.**\n"
      ],
      "metadata": {
        "id": "ewytIF3nUWO3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px6mmsM_pPi6"
      },
      "outputs": [],
      "source": [
        "# Pad sequences\n",
        "max_len = 400\n",
        "X_train_padded = pad_sequences(X_train_sequence, maxlen=max_len)\n",
        "X_test_padded = pad_sequences(X_test_sequence, maxlen=max_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load models\n",
        "\n",
        "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
        "fasttext_model = FastText.load_fasttext_format(\"/content/drive/MyDrive/DeepLearning/HW/HW4/wiki.en/wiki.en.bin\")\n",
        "glove_model = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/DeepLearning/HW/HW4/glove.6B.300d.txt\", binary=False, no_header=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fU3dXlBHQro",
        "outputId": "378ef897-2077-452b-efbb-8462f2f2dfd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-34c14da794a0>:4: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
            "  fasttext_model = FastText.load_fasttext_format(\"/content/drive/MyDrive/DeepLearning/HW/HW4/wiki.en/wiki.en.bin\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xo-fm86BpxKR"
      },
      "outputs": [],
      "source": [
        "# Word Embeddings\n",
        "embeddings = {\n",
        "    'FastText': fasttext_model,\n",
        "    'Word2Vec': word2vec_model,\n",
        "    'GloVe': glove_model,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkNTvj6Wq5Na"
      },
      "outputs": [],
      "source": [
        "# Sequential Models\n",
        "models = {\n",
        "    'RNN': SimpleRNN,\n",
        "    'LSTM': LSTM,\n",
        "    'GRU': GRU,\n",
        "    'Bi-RNN': lambda units, **kwargs: Bidirectional(SimpleRNN(units, **kwargs)),\n",
        "    'Bi-LSTM': lambda units, **kwargs: Bidirectional(LSTM(units, **kwargs)),\n",
        "    'Bi-GRU': lambda units, **kwargs: Bidirectional(GRU(units, **kwargs)),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOhOyEMQwl9u"
      },
      "outputs": [],
      "source": [
        "def load_pretrained_embedding_matrix(embedding_model, word_index, max_words, embedding_dim):\n",
        "    # Initialize the embedding matrix with zeros\n",
        "    embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "\n",
        "    # Iterate over the words in the tokenizer's word index\n",
        "    for word, i in word_index.items():\n",
        "        if i < max_words:\n",
        "            try:\n",
        "                # Get the embedding vector for the word from the pre-trained model\n",
        "                if isinstance(embedding_model, dict):\n",
        "                    embedding_vector = embedding_model.get(word) # For GloVe\n",
        "                else:\n",
        "                    #, FastText, Doc2Vec, Word2Vec\n",
        "                    embedding_vector = embedding_model[word]\n",
        "\n",
        "                if embedding_vector is not None:\n",
        "                    embedding_matrix[i] = embedding_vector\n",
        "            except KeyError:\n",
        "                # Handle the case where the word is not in the pre-trained model vocabulary\n",
        "                pass\n",
        "\n",
        "    return embedding_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2c6buY_CBd3"
      },
      "outputs": [],
      "source": [
        "# Define the model checkpoint callback\n",
        "checkpoint_filepath = '/content/drive/MyDrive/DeepLearning/HW/HW4/best_model_doc2vec.h5'\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_best_only=True,\n",
        "    monitor='val_accuracy',  # Choose the metric to monitor for saving the best model\n",
        "    mode='max',  # Use 'max' if the metric should be maximized, 'min' if minimized\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzS3pYtpCBaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bace717f-d469-44e5-aa69-b91772677191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embedding_name, embedding_model =  FastText FastText<vocab=2519370, vector_size=300, alpha=0.025>\n",
            "model_name, model_type =  RNN <class 'keras.src.layers.rnn.simple_rnn.SimpleRNN'>\n",
            "embedding matrix of embedding FastText :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.13328807 -0.05767915 -0.33409759 ...  0.13057882 -0.27169716\n",
            "   0.08316325]\n",
            " [-0.18028842 -0.13397793 -0.36935762 ...  0.19898225 -0.36105326\n",
            "   0.1683947 ]\n",
            " ...\n",
            " [-0.14113562  0.12844351 -0.09726463 ...  0.29306051  0.80443078\n",
            "  -0.08794205]\n",
            " [-0.11768486 -0.0247553  -0.15214039 ...  0.58489919  0.29173273\n",
            "   0.1966266 ]\n",
            " [ 0.05685775  0.27686319 -0.03135364 ...  0.68205708  0.30812877\n",
            "   0.58232498]]\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " simple_rnn_10 (SimpleRNN)   (None, 128)               54912     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24727341 (94.33 MB)\n",
            "Trainable params: 55041 (215.00 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.66263, saving model to /content/drive/MyDrive/DeepLearning/HW/HW4/best_model_doc2vec.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.66263\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.66263 to 0.77113, saving model to /content/drive/MyDrive/DeepLearning/HW/HW4/best_model_doc2vec.h5\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.77113\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.77113\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.77113\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.77113\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.77113\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.77113\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.77113\n",
            "model_name RNN with FastText has accuracy of 0.5267000198364258\n",
            "313/313 [==============================] - 8s 26ms/step\n",
            "Classification Report for RNN with FastText:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.07      0.12      4961\n",
            "           1       0.52      0.98      0.68      5039\n",
            "\n",
            "    accuracy                           0.53     10000\n",
            "   macro avg       0.64      0.52      0.40     10000\n",
            "weighted avg       0.64      0.53      0.40     10000\n",
            "\n",
            "Confusion Matrix for RNN with FastText:\n",
            "[[ 323 4638]\n",
            " [  95 4944]]\n",
            "model_name, model_type =  LSTM <class 'keras.src.layers.rnn.lstm.LSTM'>\n",
            "embedding matrix of embedding FastText :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.13328807 -0.05767915 -0.33409759 ...  0.13057882 -0.27169716\n",
            "   0.08316325]\n",
            " [-0.18028842 -0.13397793 -0.36935762 ...  0.19898225 -0.36105326\n",
            "   0.1683947 ]\n",
            " ...\n",
            " [-0.14113562  0.12844351 -0.09726463 ...  0.29306051  0.80443078\n",
            "  -0.08794205]\n",
            " [-0.11768486 -0.0247553  -0.15214039 ...  0.58489919  0.29173273\n",
            "   0.1966266 ]\n",
            " [ 0.05685775  0.27686319 -0.03135364 ...  0.68205708  0.30812877\n",
            "   0.58232498]]\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " lstm_12 (LSTM)              (None, 128)               219648    \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24892077 (94.96 MB)\n",
            "Trainable params: 219777 (858.50 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy improved from 0.77113 to 0.84650, saving model to /content/drive/MyDrive/DeepLearning/HW/HW4/best_model_doc2vec.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2: val_accuracy improved from 0.84650 to 0.87050, saving model to /content/drive/MyDrive/DeepLearning/HW/HW4/best_model_doc2vec.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.87050 to 0.88687, saving model to /content/drive/MyDrive/DeepLearning/HW/HW4/best_model_doc2vec.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.88687 to 0.89237, saving model to /content/drive/MyDrive/DeepLearning/HW/HW4/best_model_doc2vec.h5\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89237\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89237\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89237\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89237\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89237\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89237\n",
            "model_name LSTM with FastText has accuracy of 0.8784000277519226\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Classification Report for LSTM with FastText:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88      4961\n",
            "           1       0.87      0.89      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for LSTM with FastText:\n",
            "[[4316  645]\n",
            " [ 571 4468]]\n",
            "model_name, model_type =  GRU <class 'keras.src.layers.rnn.gru.GRU'>\n",
            "embedding matrix of embedding FastText :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.13328807 -0.05767915 -0.33409759 ...  0.13057882 -0.27169716\n",
            "   0.08316325]\n",
            " [-0.18028842 -0.13397793 -0.36935762 ...  0.19898225 -0.36105326\n",
            "   0.1683947 ]\n",
            " ...\n",
            " [-0.14113562  0.12844351 -0.09726463 ...  0.29306051  0.80443078\n",
            "  -0.08794205]\n",
            " [-0.11768486 -0.0247553  -0.15214039 ...  0.58489919  0.29173273\n",
            "   0.1966266 ]\n",
            " [ 0.05685775  0.27686319 -0.03135364 ...  0.68205708  0.30812877\n",
            "   0.58232498]]\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " gru_11 (GRU)                (None, 128)               165120    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24837549 (94.75 MB)\n",
            "Trainable params: 165249 (645.50 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89237\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89237\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.89237 to 0.89400, saving model to /content/drive/MyDrive/DeepLearning/HW/HW4/best_model_doc2vec.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89400\n",
            "model_name GRU with FastText has accuracy of 0.8790000081062317\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Classification Report for GRU with FastText:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88      4961\n",
            "           1       0.90      0.86      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for GRU with FastText:\n",
            "[[4455  506]\n",
            " [ 704 4335]]\n",
            "model_name, model_type =  Bi-RNN <function <lambda> at 0x7c327d3a8af0>\n",
            "embedding matrix of embedding FastText :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.13328807 -0.05767915 -0.33409759 ...  0.13057882 -0.27169716\n",
            "   0.08316325]\n",
            " [-0.18028842 -0.13397793 -0.36935762 ...  0.19898225 -0.36105326\n",
            "   0.1683947 ]\n",
            " ...\n",
            " [-0.14113562  0.12844351 -0.09726463 ...  0.29306051  0.80443078\n",
            "  -0.08794205]\n",
            " [-0.11768486 -0.0247553  -0.15214039 ...  0.58489919  0.29173273\n",
            "   0.1966266 ]\n",
            " [ 0.05685775  0.27686319 -0.03135364 ...  0.68205708  0.30812877\n",
            "   0.58232498]]\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " bidirectional_19 (Bidirect  (None, 256)               109824    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24782381 (94.54 MB)\n",
            "Trainable params: 110081 (430.00 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89400\n",
            "model_name Bi-RNN with FastText has accuracy of 0.6388000249862671\n",
            "313/313 [==============================] - 17s 50ms/step\n",
            "Classification Report for Bi-RNN with FastText:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.65      0.64      4961\n",
            "           1       0.64      0.63      0.64      5039\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.64      0.64      0.64     10000\n",
            "weighted avg       0.64      0.64      0.64     10000\n",
            "\n",
            "Confusion Matrix for Bi-RNN with FastText:\n",
            "[[3206 1755]\n",
            " [1857 3182]]\n",
            "model_name, model_type =  Bi-LSTM <function <lambda> at 0x7c327d3a8a60>\n",
            "embedding matrix of embedding FastText :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.13328807 -0.05767915 -0.33409759 ...  0.13057882 -0.27169716\n",
            "   0.08316325]\n",
            " [-0.18028842 -0.13397793 -0.36935762 ...  0.19898225 -0.36105326\n",
            "   0.1683947 ]\n",
            " ...\n",
            " [-0.14113562  0.12844351 -0.09726463 ...  0.29306051  0.80443078\n",
            "  -0.08794205]\n",
            " [-0.11768486 -0.0247553  -0.15214039 ...  0.58489919  0.29173273\n",
            "   0.1966266 ]\n",
            " [ 0.05685775  0.27686319 -0.03135364 ...  0.68205708  0.30812877\n",
            "   0.58232498]]\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " bidirectional_20 (Bidirect  (None, 256)               439296    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25111853 (95.79 MB)\n",
            "Trainable params: 439553 (1.68 MB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89400\n",
            "model_name Bi-LSTM with FastText has accuracy of 0.8797000050544739\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "Classification Report for Bi-LSTM with FastText:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.87      4961\n",
            "           1       0.86      0.91      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for Bi-LSTM with FastText:\n",
            "[[4208  753]\n",
            " [ 450 4589]]\n",
            "model_name, model_type =  Bi-GRU <function <lambda> at 0x7c327d3a8940>\n",
            "embedding matrix of embedding FastText :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.13328807 -0.05767915 -0.33409759 ...  0.13057882 -0.27169716\n",
            "   0.08316325]\n",
            " [-0.18028842 -0.13397793 -0.36935762 ...  0.19898225 -0.36105326\n",
            "   0.1683947 ]\n",
            " ...\n",
            " [-0.14113562  0.12844351 -0.09726463 ...  0.29306051  0.80443078\n",
            "  -0.08794205]\n",
            " [-0.11768486 -0.0247553  -0.15214039 ...  0.58489919  0.29173273\n",
            "   0.1966266 ]\n",
            " [ 0.05685775  0.27686319 -0.03135364 ...  0.68205708  0.30812877\n",
            "   0.58232498]]\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " bidirectional_21 (Bidirect  (None, 256)               330240    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25002797 (95.38 MB)\n",
            "Trainable params: 330497 (1.26 MB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89400\n",
            "model_name Bi-GRU with FastText has accuracy of 0.8772000074386597\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "Classification Report for Bi-GRU with FastText:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87      4961\n",
            "           1       0.87      0.89      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for Bi-GRU with FastText:\n",
            "[[4293  668]\n",
            " [ 560 4479]]\n",
            "embedding_name, embedding_model =  Word2Vec KeyedVectors<vector_size=300, 3000000 keys>\n",
            "model_name, model_type =  RNN <class 'keras.src.layers.rnn.simple_rnn.SimpleRNN'>\n",
            "embedding matrix of embedding Word2Vec :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.17480469 -0.10986328 -0.20019531 ...  0.07958984  0.02807617\n",
            "  -0.02026367]\n",
            " [-0.0038147  -0.01916504 -0.13085938 ...  0.06347656  0.03417969\n",
            "   0.03344727]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " simple_rnn_12 (SimpleRNN)   (None, 128)               54912     \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24727341 (94.33 MB)\n",
            "Trainable params: 55041 (215.00 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89400\n",
            "model_name RNN with Word2Vec has accuracy of 0.772599995136261\n",
            "313/313 [==============================] - 9s 27ms/step\n",
            "Classification Report for RNN with Word2Vec:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.64      0.74      4961\n",
            "           1       0.72      0.90      0.80      5039\n",
            "\n",
            "    accuracy                           0.77     10000\n",
            "   macro avg       0.79      0.77      0.77     10000\n",
            "weighted avg       0.79      0.77      0.77     10000\n",
            "\n",
            "Confusion Matrix for RNN with Word2Vec:\n",
            "[[3199 1762]\n",
            " [ 512 4527]]\n",
            "model_name, model_type =  LSTM <class 'keras.src.layers.rnn.lstm.LSTM'>\n",
            "embedding matrix of embedding Word2Vec :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.17480469 -0.10986328 -0.20019531 ...  0.07958984  0.02807617\n",
            "  -0.02026367]\n",
            " [-0.0038147  -0.01916504 -0.13085938 ...  0.06347656  0.03417969\n",
            "   0.03344727]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " lstm_14 (LSTM)              (None, 128)               219648    \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24892077 (94.96 MB)\n",
            "Trainable params: 219777 (858.50 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89400\n",
            "model_name LSTM with Word2Vec has accuracy of 0.8751999735832214\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Classification Report for LSTM with Word2Vec:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.85      0.87      4961\n",
            "           1       0.86      0.90      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for LSTM with Word2Vec:\n",
            "[[4230  731]\n",
            " [ 517 4522]]\n",
            "model_name, model_type =  GRU <class 'keras.src.layers.rnn.gru.GRU'>\n",
            "embedding matrix of embedding Word2Vec :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.17480469 -0.10986328 -0.20019531 ...  0.07958984  0.02807617\n",
            "  -0.02026367]\n",
            " [-0.0038147  -0.01916504 -0.13085938 ...  0.06347656  0.03417969\n",
            "   0.03344727]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " gru_13 (GRU)                (None, 128)               165120    \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24837549 (94.75 MB)\n",
            "Trainable params: 165249 (645.50 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89400\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.89400 to 0.89650, saving model to /content/drive/MyDrive/DeepLearning/HW/HW4/best_model_doc2vec.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name GRU with Word2Vec has accuracy of 0.8798999786376953\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Classification Report for GRU with Word2Vec:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.91      0.88      4961\n",
            "           1       0.91      0.85      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for GRU with Word2Vec:\n",
            "[[4521  440]\n",
            " [ 761 4278]]\n",
            "model_name, model_type =  Bi-RNN <function <lambda> at 0x7c327d3a8af0>\n",
            "embedding matrix of embedding Word2Vec :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.17480469 -0.10986328 -0.20019531 ...  0.07958984  0.02807617\n",
            "  -0.02026367]\n",
            " [-0.0038147  -0.01916504 -0.13085938 ...  0.06347656  0.03417969\n",
            "   0.03344727]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " bidirectional_22 (Bidirect  (None, 256)               109824    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24782381 (94.54 MB)\n",
            "Trainable params: 110081 (430.00 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name Bi-RNN with Word2Vec has accuracy of 0.6664999723434448\n",
            "313/313 [==============================] - 16s 51ms/step\n",
            "Classification Report for Bi-RNN with Word2Vec:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.59      0.64      4961\n",
            "           1       0.65      0.74      0.69      5039\n",
            "\n",
            "    accuracy                           0.67     10000\n",
            "   macro avg       0.67      0.67      0.66     10000\n",
            "weighted avg       0.67      0.67      0.66     10000\n",
            "\n",
            "Confusion Matrix for Bi-RNN with Word2Vec:\n",
            "[[2941 2020]\n",
            " [1315 3724]]\n",
            "model_name, model_type =  Bi-LSTM <function <lambda> at 0x7c327d3a8a60>\n",
            "embedding matrix of embedding Word2Vec :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.17480469 -0.10986328 -0.20019531 ...  0.07958984  0.02807617\n",
            "  -0.02026367]\n",
            " [-0.0038147  -0.01916504 -0.13085938 ...  0.06347656  0.03417969\n",
            "   0.03344727]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_10 (Embedding)    (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " bidirectional_23 (Bidirect  (None, 256)               439296    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25111853 (95.79 MB)\n",
            "Trainable params: 439553 (1.68 MB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name Bi-LSTM with Word2Vec has accuracy of 0.8920000195503235\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "Classification Report for Bi-LSTM with Word2Vec:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.90      0.89      4961\n",
            "           1       0.90      0.89      0.89      5039\n",
            "\n",
            "    accuracy                           0.89     10000\n",
            "   macro avg       0.89      0.89      0.89     10000\n",
            "weighted avg       0.89      0.89      0.89     10000\n",
            "\n",
            "Confusion Matrix for Bi-LSTM with Word2Vec:\n",
            "[[4445  516]\n",
            " [ 564 4475]]\n",
            "model_name, model_type =  Bi-GRU <function <lambda> at 0x7c327d3a8940>\n",
            "embedding matrix of embedding Word2Vec :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.17480469 -0.10986328 -0.20019531 ...  0.07958984  0.02807617\n",
            "  -0.02026367]\n",
            " [-0.0038147  -0.01916504 -0.13085938 ...  0.06347656  0.03417969\n",
            "   0.03344727]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " bidirectional_24 (Bidirect  (None, 256)               330240    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25002797 (95.38 MB)\n",
            "Trainable params: 330497 (1.26 MB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name Bi-GRU with Word2Vec has accuracy of 0.8805000185966492\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "Classification Report for Bi-GRU with Word2Vec:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88      4961\n",
            "           1       0.88      0.88      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for Bi-GRU with Word2Vec:\n",
            "[[4365  596]\n",
            " [ 599 4440]]\n",
            "embedding_name, embedding_model =  GloVe KeyedVectors<vector_size=300, 400000 keys>\n",
            "model_name, model_type =  RNN <class 'keras.src.layers.rnn.simple_rnn.SimpleRNN'>\n",
            "embedding matrix of embedding GloVe :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.138      -0.12203     0.0054643  ...  0.19934     0.057473\n",
            "  -0.023767  ]\n",
            " [-0.030351   -0.17344999 -0.097576   ...  0.26174     0.083567\n",
            "  -0.19064   ]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.72096997 -0.40970999 -0.28687    ...  0.38811001  0.090473\n",
            "   0.087134  ]]\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " simple_rnn_14 (SimpleRNN)   (None, 128)               54912     \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24727341 (94.33 MB)\n",
            "Trainable params: 55041 (215.00 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name RNN with GloVe has accuracy of 0.7426000237464905\n",
            "313/313 [==============================] - 8s 26ms/step\n",
            "Classification Report for RNN with GloVe:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.64      0.71      4961\n",
            "           1       0.70      0.84      0.77      5039\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.75      0.74      0.74     10000\n",
            "weighted avg       0.75      0.74      0.74     10000\n",
            "\n",
            "Confusion Matrix for RNN with GloVe:\n",
            "[[3169 1792]\n",
            " [ 782 4257]]\n",
            "model_name, model_type =  LSTM <class 'keras.src.layers.rnn.lstm.LSTM'>\n",
            "embedding matrix of embedding GloVe :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.138      -0.12203     0.0054643  ...  0.19934     0.057473\n",
            "  -0.023767  ]\n",
            " [-0.030351   -0.17344999 -0.097576   ...  0.26174     0.083567\n",
            "  -0.19064   ]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.72096997 -0.40970999 -0.28687    ...  0.38811001  0.090473\n",
            "   0.087134  ]]\n",
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " lstm_16 (LSTM)              (None, 128)               219648    \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24892077 (94.96 MB)\n",
            "Trainable params: 219777 (858.50 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name LSTM with GloVe has accuracy of 0.8820000290870667\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Classification Report for LSTM with GloVe:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.88      4961\n",
            "           1       0.88      0.89      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for LSTM with GloVe:\n",
            "[[4345  616]\n",
            " [ 564 4475]]\n",
            "model_name, model_type =  GRU <class 'keras.src.layers.rnn.gru.GRU'>\n",
            "embedding matrix of embedding GloVe :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.138      -0.12203     0.0054643  ...  0.19934     0.057473\n",
            "  -0.023767  ]\n",
            " [-0.030351   -0.17344999 -0.097576   ...  0.26174     0.083567\n",
            "  -0.19064   ]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.72096997 -0.40970999 -0.28687    ...  0.38811001  0.090473\n",
            "   0.087134  ]]\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_14 (Embedding)    (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " gru_15 (GRU)                (None, 128)               165120    \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24837549 (94.75 MB)\n",
            "Trainable params: 165249 (645.50 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name GRU with GloVe has accuracy of 0.8791000247001648\n",
            "313/313 [==============================] - 2s 6ms/step\n",
            "Classification Report for GRU with GloVe:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.90      0.88      4961\n",
            "           1       0.90      0.86      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for GRU with GloVe:\n",
            "[[4479  482]\n",
            " [ 727 4312]]\n",
            "model_name, model_type =  Bi-RNN <function <lambda> at 0x7c327d3a8af0>\n",
            "embedding matrix of embedding GloVe :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.138      -0.12203     0.0054643  ...  0.19934     0.057473\n",
            "  -0.023767  ]\n",
            " [-0.030351   -0.17344999 -0.097576   ...  0.26174     0.083567\n",
            "  -0.19064   ]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.72096997 -0.40970999 -0.28687    ...  0.38811001  0.090473\n",
            "   0.087134  ]]\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_15 (Embedding)    (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " bidirectional_25 (Bidirect  (None, 256)               109824    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24782381 (94.54 MB)\n",
            "Trainable params: 110081 (430.00 KB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name Bi-RNN with GloVe has accuracy of 0.642799973487854\n",
            "313/313 [==============================] - 16s 50ms/step\n",
            "Classification Report for Bi-RNN with GloVe:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.61      0.63      4961\n",
            "           1       0.64      0.68      0.66      5039\n",
            "\n",
            "    accuracy                           0.64     10000\n",
            "   macro avg       0.64      0.64      0.64     10000\n",
            "weighted avg       0.64      0.64      0.64     10000\n",
            "\n",
            "Confusion Matrix for Bi-RNN with GloVe:\n",
            "[[3010 1951]\n",
            " [1621 3418]]\n",
            "model_name, model_type =  Bi-LSTM <function <lambda> at 0x7c327d3a8a60>\n",
            "embedding matrix of embedding GloVe :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.138      -0.12203     0.0054643  ...  0.19934     0.057473\n",
            "  -0.023767  ]\n",
            " [-0.030351   -0.17344999 -0.097576   ...  0.26174     0.083567\n",
            "  -0.19064   ]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.72096997 -0.40970999 -0.28687    ...  0.38811001  0.090473\n",
            "   0.087134  ]]\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_16 (Embedding)    (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " bidirectional_26 (Bidirect  (None, 256)               439296    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25111853 (95.79 MB)\n",
            "Trainable params: 439553 (1.68 MB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name Bi-LSTM with GloVe has accuracy of 0.8765000104904175\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "Classification Report for Bi-LSTM with GloVe:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.86      0.87      4961\n",
            "           1       0.87      0.89      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for Bi-LSTM with GloVe:\n",
            "[[4267  694]\n",
            " [ 541 4498]]\n",
            "model_name, model_type =  Bi-GRU <function <lambda> at 0x7c327d3a8940>\n",
            "embedding matrix of embedding GloVe :  [[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [-0.138      -0.12203     0.0054643  ...  0.19934     0.057473\n",
            "  -0.023767  ]\n",
            " [-0.030351   -0.17344999 -0.097576   ...  0.26174     0.083567\n",
            "  -0.19064   ]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.72096997 -0.40970999 -0.28687    ...  0.38811001  0.090473\n",
            "   0.087134  ]]\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_17 (Embedding)    (None, 400, 300)          24672300  \n",
            "                                                                 \n",
            " bidirectional_27 (Bidirect  (None, 256)               330240    \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25002797 (95.38 MB)\n",
            "Trainable params: 330497 (1.26 MB)\n",
            "Non-trainable params: 24672300 (94.12 MB)\n",
            "_________________________________________________________________\n",
            "\n",
            "Epoch 1: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 2: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 3: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 5: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.89650\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.89650\n",
            "model_name Bi-GRU with GloVe has accuracy of 0.8823000192642212\n",
            "313/313 [==============================] - 4s 12ms/step\n",
            "Classification Report for Bi-GRU with GloVe:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.89      0.88      4961\n",
            "           1       0.89      0.88      0.88      5039\n",
            "\n",
            "    accuracy                           0.88     10000\n",
            "   macro avg       0.88      0.88      0.88     10000\n",
            "weighted avg       0.88      0.88      0.88     10000\n",
            "\n",
            "Confusion Matrix for Bi-GRU with GloVe:\n",
            "[[4395  566]\n",
            " [ 611 4428]]\n"
          ]
        }
      ],
      "source": [
        "for embedding_name, embedding_model in embeddings.items():\n",
        "    print('embedding_name, embedding_model = ', embedding_name, embedding_model)\n",
        "    for model_name, model_type in models.items():\n",
        "        print('model_name, model_type = ', model_name, model_type)\n",
        "\n",
        "        # Build the model\n",
        "        model = Sequential()\n",
        "\n",
        "        if embedding_name == 'Word2Vec' :\n",
        "            # Check if embedding_model is a Word2Vec model\n",
        "            if isinstance(embedding_model, Word2Vec):\n",
        "                embedding_matrix_word2vec = load_pretrained_embedding_matrix(embedding_model, tokenizer.word_index, max_words, embedding_model.vector_size)\n",
        "            else:\n",
        "                embedding_matrix_word2vec = load_pretrained_embedding_matrix(embedding_model, tokenizer.word_index, max_words, len(embedding_model['the']))\n",
        "            embedding_matrix = embedding_matrix_word2vec\n",
        "\n",
        "            #embedding_matrix_word2vec = load_pretrained_embedding_matrix(word2vec_model.wv, tokenizer.word_index, max_words, word2vec_model.vector_size)\n",
        "            #embedding_matrix = embedding_matrix_word2vec\n",
        "        elif embedding_name == 'FastText' :\n",
        "            embedding_matrix_fasttext = load_pretrained_embedding_matrix(fasttext_model.wv, tokenizer.word_index, max_words, fasttext_model.vector_size)\n",
        "            embedding_matrix = embedding_matrix_fasttext\n",
        "        elif embedding_name == 'GloVe':\n",
        "            embedding_matrix_glove = load_pretrained_embedding_matrix(glove_model, tokenizer.word_index, max_words, len(glove_model['the']))\n",
        "            embedding_matrix = embedding_matrix_glove\n",
        "\n",
        "        print(f'embedding matrix of embedding {embedding_name} : ', embedding_matrix)\n",
        "        embedding_layer = Embedding(\n",
        "            input_dim=max_words,\n",
        "            output_dim=embedding_matrix.shape[1],\n",
        "            input_length=max_len,\n",
        "            trainable=False,\n",
        "            weights=[embedding_matrix],\n",
        "        )\n",
        "        model.add(embedding_layer)\n",
        "        model.add(model_type(128))  # Adjust units as needed\n",
        "\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "        model.summary()\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train_padded, y_train, epochs=10, batch_size=32, validation_split=0.2, verbose=0, callbacks=[model_checkpoint_callback,reduce_lr,early_stop])\n",
        "\n",
        "        # Evaluate the model\n",
        "        _, accuracy = model.evaluate(X_test_padded, y_test, verbose=0)\n",
        "\n",
        "        print(f\"model_name {model_name} with {embedding_name} has accuracy of {accuracy}\")\n",
        "        results.append({'Embedding': embedding_name, 'Model': model_name, 'Accuracy': accuracy * 100})\n",
        "\n",
        "        # Evaluate the model\n",
        "        y_pred = model.predict(X_test_padded)\n",
        "\n",
        "        # Convert probabilities to class labels\n",
        "        y_pred_labels = (y_pred > 0.5).astype(int)\n",
        "\n",
        "        # Print classification report and confusion matrix\n",
        "        print(f\"Classification Report for {model_name} with {embedding_name}:\")\n",
        "        print(classification_report(y_test, y_pred_labels))\n",
        "\n",
        "        print(f\"Confusion Matrix for {model_name} with {embedding_name}:\")\n",
        "        print(confusion_matrix(y_test, y_pred_labels))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)    # Many Doc2Vec values are coming because of multiple trials and results_df was not reset.\n",
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vVRICTo90PKb",
        "outputId": "bc79b366-cbd1-4b81-bb6b-467cf8fc6e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Embedding    Model   Accuracy\n",
              "0    Doc2Vec      RNN  84.289998\n",
              "1    Doc2Vec     LSTM  83.539999\n",
              "2    Doc2Vec      GRU  83.950001\n",
              "3    Doc2Vec      RNN  84.490001\n",
              "4    Doc2Vec     LSTM  83.649999\n",
              "5    Doc2Vec      GRU  84.079999\n",
              "6    Doc2Vec   Bi-RNN  84.560001\n",
              "7    Doc2Vec      RNN  84.590000\n",
              "8    Doc2Vec     LSTM  83.965653\n",
              "9    Doc2Vec      GRU  83.935702\n",
              "10   Doc2Vec   Bi-RNN  51.126873\n",
              "11   Doc2Vec  Bi-LSTM  51.106250\n",
              "12   Doc2Vec   Bi-GRU  51.125002\n",
              "13   Doc2Vec   Bi-GRU  84.550000\n",
              "14   Doc2Vec      RNN  84.310000\n",
              "15   Doc2Vec      RNN  84.570000\n",
              "16   Doc2Vec     LSTM  84.210000\n",
              "17   Doc2Vec      GRU  83.560000\n",
              "18   Doc2Vec   Bi-RNN  84.460000\n",
              "19   Doc2Vec  Bi-LSTM  83.200000\n",
              "20   Doc2Vec   Bi-GRU  83.430000\n",
              "21  FastText      RNN  52.670002\n",
              "22  FastText     LSTM  87.840003\n",
              "23  FastText      GRU  87.900001\n",
              "24  FastText   Bi-RNN  63.880002\n",
              "25  FastText  Bi-LSTM  87.970001\n",
              "26  FastText   Bi-GRU  87.720001\n",
              "27  Word2Vec      RNN  77.260000\n",
              "28  Word2Vec     LSTM  87.519997\n",
              "29  Word2Vec      GRU  87.989998\n",
              "30  Word2Vec   Bi-RNN  66.649997\n",
              "31  Word2Vec  Bi-LSTM  89.200002\n",
              "32  Word2Vec   Bi-GRU  88.050002\n",
              "33     GloVe      RNN  74.260002\n",
              "34     GloVe     LSTM  88.200003\n",
              "35     GloVe      GRU  87.910002\n",
              "36     GloVe   Bi-RNN  64.279997\n",
              "37     GloVe  Bi-LSTM  87.650001\n",
              "38     GloVe   Bi-GRU  88.230002"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a8112fc6-8c1d-43dc-9d02-6ea035d354be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Embedding</th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>RNN</td>\n",
              "      <td>84.289998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>83.539999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>GRU</td>\n",
              "      <td>83.950001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>RNN</td>\n",
              "      <td>84.490001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>83.649999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>GRU</td>\n",
              "      <td>84.079999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>84.560001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>RNN</td>\n",
              "      <td>84.590000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>83.965653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>GRU</td>\n",
              "      <td>83.935702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>51.126873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>51.106250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>51.125002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>84.550000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>RNN</td>\n",
              "      <td>84.310000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>RNN</td>\n",
              "      <td>84.570000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>84.210000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>GRU</td>\n",
              "      <td>83.560000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>84.460000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>83.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>83.430000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>FastText</td>\n",
              "      <td>RNN</td>\n",
              "      <td>52.670002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>FastText</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>87.840003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>FastText</td>\n",
              "      <td>GRU</td>\n",
              "      <td>87.900001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>FastText</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>63.880002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>FastText</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>87.970001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>FastText</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>87.720001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>RNN</td>\n",
              "      <td>77.260000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>87.519997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>GRU</td>\n",
              "      <td>87.989998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>66.649997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>89.200002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>88.050002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>RNN</td>\n",
              "      <td>74.260002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>88.200003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>GRU</td>\n",
              "      <td>87.910002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>64.279997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>87.650001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>88.230002</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a8112fc6-8c1d-43dc-9d02-6ea035d354be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a8112fc6-8c1d-43dc-9d02-6ea035d354be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a8112fc6-8c1d-43dc-9d02-6ea035d354be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-db500638-3c6f-478d-88f6-ce3ab6e2659e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db500638-3c6f-478d-88f6-ce3ab6e2659e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-db500638-3c6f-478d-88f6-ce3ab6e2659e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_75cfc3cb-c925-4b80-b62a-55085b63e681\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_75cfc3cb-c925-4b80-b62a-55085b63e681 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Embedding and Model, and get the row with the highest accuracy for each group\n",
        "max_accuracy_rows = results_df.groupby(['Embedding', 'Model'], as_index=False)['Accuracy'].idxmax()\n",
        "\n",
        "# Extract the index values from the resulting DataFrame\n",
        "max_accuracy_indices = max_accuracy_rows['Accuracy']\n",
        "\n",
        "# Create a new DataFrame with the rows corresponding to the highest accuracies\n",
        "max_accuracy_df = results_df.loc[max_accuracy_indices].copy()  # Create a copy to avoid SettingWithCopyWarning\n",
        "\n",
        "# Convert 'Accuracy' column to percentage and round to 2 decimal places\n",
        "max_accuracy_df['Accuracy'] = (max_accuracy_df['Accuracy']).round(2)\n",
        "\n",
        "# Reset the index of the resulting DataFrame\n",
        "max_accuracy_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Sort the DataFrame in descending order based on 'Accuracy'\n",
        "max_accuracy_df.sort_values(by='Accuracy', ascending=False, inplace=True)\n"
      ],
      "metadata": {
        "id": "tFgHVM1-2JtF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q1a. RESULTS**"
      ],
      "metadata": {
        "id": "n7a4VKGLYub-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_accuracy_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 802
        },
        "id": "lMp4C1KC3rbs",
        "outputId": "f42049ea-9c11-43b1-f5d7-7ac0a9f012f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Embedding    Model  Accuracy\n",
              "19  Word2Vec  Bi-LSTM     89.20\n",
              "12     GloVe   Bi-GRU     88.23\n",
              "16     GloVe     LSTM     88.20\n",
              "18  Word2Vec   Bi-GRU     88.05\n",
              "21  Word2Vec      GRU     87.99\n",
              "7   FastText  Bi-LSTM     87.97\n",
              "15     GloVe      GRU     87.91\n",
              "9   FastText      GRU     87.90\n",
              "10  FastText     LSTM     87.84\n",
              "6   FastText   Bi-GRU     87.72\n",
              "13     GloVe  Bi-LSTM     87.65\n",
              "22  Word2Vec     LSTM     87.52\n",
              "5    Doc2Vec      RNN     84.59\n",
              "2    Doc2Vec   Bi-RNN     84.56\n",
              "0    Doc2Vec   Bi-GRU     84.55\n",
              "4    Doc2Vec     LSTM     84.21\n",
              "3    Doc2Vec      GRU     84.08\n",
              "1    Doc2Vec  Bi-LSTM     83.20\n",
              "23  Word2Vec      RNN     77.26\n",
              "17     GloVe      RNN     74.26\n",
              "20  Word2Vec   Bi-RNN     66.65\n",
              "14     GloVe   Bi-RNN     64.28\n",
              "8   FastText   Bi-RNN     63.88\n",
              "11  FastText      RNN     52.67"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86a5a715-1f4b-4246-b660-da7f74ef8fe5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Embedding</th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>89.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>88.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>88.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>88.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>GRU</td>\n",
              "      <td>87.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>FastText</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>87.97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>GRU</td>\n",
              "      <td>87.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>FastText</td>\n",
              "      <td>GRU</td>\n",
              "      <td>87.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>FastText</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>87.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>FastText</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>87.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>87.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>87.52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>RNN</td>\n",
              "      <td>84.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>84.56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-GRU</td>\n",
              "      <td>84.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>LSTM</td>\n",
              "      <td>84.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>GRU</td>\n",
              "      <td>84.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Doc2Vec</td>\n",
              "      <td>Bi-LSTM</td>\n",
              "      <td>83.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>RNN</td>\n",
              "      <td>77.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>RNN</td>\n",
              "      <td>74.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Word2Vec</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>66.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>GloVe</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>64.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>FastText</td>\n",
              "      <td>Bi-RNN</td>\n",
              "      <td>63.88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>FastText</td>\n",
              "      <td>RNN</td>\n",
              "      <td>52.67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86a5a715-1f4b-4246-b660-da7f74ef8fe5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-86a5a715-1f4b-4246-b660-da7f74ef8fe5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-86a5a715-1f4b-4246-b660-da7f74ef8fe5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eb2721e8-bc3f-4ea8-837e-061a10f71a0f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eb2721e8-bc3f-4ea8-837e-061a10f71a0f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eb2721e8-bc3f-4ea8-837e-061a10f71a0f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_26f1acbe-c066-44b5-90e7-81641c0a3d9d\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('max_accuracy_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_26f1acbe-c066-44b5-90e7-81641c0a3d9d button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('max_accuracy_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **The Highest Performing Model is Bi-LSTM with Word2Vec embedding with accuracy of 89%**"
      ],
      "metadata": {
        "id": "YzkxNeBc3AHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv('/content/drive/MyDrive/DeepLearning/HW/HW4/results.csv')"
      ],
      "metadata": {
        "id": "FZecwF7r1I8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q1b. Use Keras embedding layer with sequential model and use cosine similarity to find the first five most similar words to \"movie\"**"
      ],
      "metadata": {
        "id": "fN9Sew-3KcDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Keras and LSTM**"
      ],
      "metadata": {
        "id": "1VWQSnxe48BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDb dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/DeepLearning/HW/HW4/IMDB_cleaned.csv')\n",
        "\n",
        "# Tokenize the entire dataset\n",
        "max_words = 5000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df['clean_review'])\n",
        "sequences = tokenizer.texts_to_sequences(df['clean_review'])\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "max_len = 100\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Build the embedding model\n",
        "embedding_dim = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the entire dataset\n",
        "model.fit(padded_sequences, df['target'], epochs=5, batch_size=32, verbose=2)\n",
        "\n",
        "# Get the word embeddings\n",
        "embedding_layer = model.layers[0]\n",
        "weights = embedding_layer.get_weights()[0]\n",
        "\n",
        "# Get the word index from the tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Function to get the vector for a word\n",
        "def get_vector(word):\n",
        "    if word in word_index and word_index[word] < max_words:\n",
        "        return weights[word_index[word]]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Function to find the most similar words to a given word using cosine similarity, excluding the word itself\n",
        "def most_similar_words_exclude(word, exclude_word, top_n=5):\n",
        "    vector1 = get_vector(word)\n",
        "    if vector1 is None:\n",
        "        return []\n",
        "\n",
        "    similarities = cosine_similarity([vector1], weights)[0]\n",
        "\n",
        "    # Find the indices of the top N most similar words (excluding the given word)\n",
        "    top_indices = np.argsort(similarities)[::-1]\n",
        "    top_words = [(list(word_index.keys())[i], similarities[i]) for i in top_indices if list(word_index.keys())[i] != exclude_word][:top_n]\n",
        "\n",
        "    return top_words\n",
        "\n",
        "# Find the most similar words to \"movie\" excluding \"movie\"\n",
        "similar_words_movie_exclude_movie = most_similar_words_exclude(\"movie\", exclude_word=\"movie\", top_n=5)\n",
        "print(f\"The most similar words to 'movie' (excluding 'movie') are: {similar_words_movie_exclude_movie}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5njinvOK_pkI",
        "outputId": "e03bad2b-0475-4aec-87ac-3771779334ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 - 54s - loss: 0.3464 - accuracy: 0.8496 - 54s/epoch - 34ms/step\n",
            "Epoch 2/5\n",
            "1563/1563 - 15s - loss: 0.2562 - accuracy: 0.8972 - 15s/epoch - 9ms/step\n",
            "Epoch 3/5\n",
            "1563/1563 - 12s - loss: 0.2164 - accuracy: 0.9139 - 12s/epoch - 8ms/step\n",
            "Epoch 4/5\n",
            "1563/1563 - 10s - loss: 0.1739 - accuracy: 0.9331 - 10s/epoch - 7ms/step\n",
            "Epoch 5/5\n",
            "1563/1563 - 11s - loss: 0.1432 - accuracy: 0.9468 - 11s/epoch - 7ms/step\n",
            "The most similar words to 'movie' (excluding 'movie') are: [('film', 1.0), ('obsession', 0.73142433), ('lord', 0.6873765), ('festival', 0.66646934), ('quest', 0.663234)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Keras + LSTM** => The most similar words to 'movie' (excluding 'movie') are: [('**film**', 1.0), ('**obsession**', 0.73142433), ('**lord**', 0.6873765), ('**festival**', 0.66646934), ('**quest**', 0.663234)]"
      ],
      "metadata": {
        "id": "QP8RZuA96gOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Keras and GRU**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lvf2zdwi4zKr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "STTlMVRJ4u6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load IMDb dataset\n",
        "df_gru = pd.read_csv('/content/drive/MyDrive/DeepLearning/HW/HW4/IMDB_cleaned.csv')\n",
        "\n",
        "# Tokenize the entire dataset\n",
        "max_words = 5000\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(df_gru['clean_review'])\n",
        "sequences = tokenizer.texts_to_sequences(df_gru['clean_review'])\n",
        "\n",
        "# Pad sequences to a fixed length\n",
        "max_len = 100\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "# Build the embedding model\n",
        "embedding_dim = 100\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=embedding_dim, input_length=max_len))\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the entire dataset\n",
        "model.fit(padded_sequences, df_gru['target'], epochs=5, batch_size=32, verbose=2)\n",
        "\n",
        "# Get the word embeddings\n",
        "embedding_layer = model.layers[0]\n",
        "weights = embedding_layer.get_weights()[0]\n",
        "\n",
        "# Get the word index from the tokenizer\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Function to get the vector for a word\n",
        "def get_vector(word):\n",
        "    if word in word_index and word_index[word] < max_words:\n",
        "        return weights[word_index[word]]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Function to find the most similar words to a given word using cosine similarity, excluding the word itself\n",
        "def most_similar_words_exclude(word, exclude_word, top_n=5):\n",
        "    vector1 = get_vector(word)\n",
        "    if vector1 is None:\n",
        "        return []\n",
        "\n",
        "    similarities = cosine_similarity([vector1], weights)[0]\n",
        "\n",
        "    # Find the indices of the top N most similar words (excluding the given word)\n",
        "    top_indices = np.argsort(similarities)[::-1]\n",
        "    top_words = [(list(word_index.keys())[i], similarities[i]) for i in top_indices if list(word_index.keys())[i] != exclude_word][:top_n]\n",
        "\n",
        "    return top_words\n",
        "\n",
        "# Find the most similar words to \"movie\" excluding \"movie\"\n",
        "similar_words_movie_exclude_movie = most_similar_words_exclude(\"movie\", exclude_word=\"movie\", top_n=5)\n",
        "print(f\"The most similar words to 'movie' (excluding 'movie') are: {similar_words_movie_exclude_movie}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5B2FFDm6flh",
        "outputId": "878d10cd-7bcc-45ac-d3e0-95834d009124"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 - 52s - loss: 0.3461 - accuracy: 0.8462 - 52s/epoch - 33ms/step\n",
            "Epoch 2/5\n",
            "1563/1563 - 13s - loss: 0.2397 - accuracy: 0.9041 - 13s/epoch - 9ms/step\n",
            "Epoch 3/5\n",
            "1563/1563 - 11s - loss: 0.1941 - accuracy: 0.9243 - 11s/epoch - 7ms/step\n",
            "Epoch 4/5\n",
            "1563/1563 - 11s - loss: 0.1566 - accuracy: 0.9402 - 11s/epoch - 7ms/step\n",
            "Epoch 5/5\n",
            "1563/1563 - 10s - loss: 0.1203 - accuracy: 0.9547 - 10s/epoch - 6ms/step\n",
            "The most similar words to 'movie' (excluding 'movie') are: [('film', 1.0), ('home', 0.6828351), ('crime', 0.67553556), ('jr', 0.6702849), ('convey', 0.65589595)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Keras + GRU** => The most similar words to 'movie' (excluding 'movie') are: [('**film**', 1.0), ('**home**', 0.6828351), ('**crime**', 0.67553556), ('**jr**', 0.6702849), ('**convey**', 0.65589595)]\n",
        "\n"
      ],
      "metadata": {
        "id": "DZfwEtBm9Gwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **With Glove Embeddings**"
      ],
      "metadata": {
        "id": "EePmDY4C7gsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained GloVe embeddings\n",
        "glove_embeddings_index = {}\n",
        "with open('/content/drive/MyDrive/DeepLearning/HW/HW4/glove.6B.300d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        glove_embeddings_index[word] = coefs\n",
        "\n",
        "# Function to get the vector for a word using GloVe embeddings\n",
        "def get_glove_vector(word):\n",
        "    return glove_embeddings_index.get(word)\n",
        "\n",
        "# Function to find the most similar words to a given word using cosine similarity with GloVe embeddings\n",
        "def most_similar_words_glove(word, exclude_word, top_n=5):\n",
        "    vector1 = get_glove_vector(word)\n",
        "    if vector1 is None:\n",
        "        return []\n",
        "\n",
        "    similarities = cosine_similarity([vector1], [glove_embeddings_index[w] for w in glove_embeddings_index if w != exclude_word])[0]\n",
        "\n",
        "    # Find the indices of the top N most similar words\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_n]\n",
        "\n",
        "    # Get the words and their similarity scores\n",
        "    similar_words = [(list(glove_embeddings_index.keys())[i], similarities[i]) for i in top_indices]\n",
        "\n",
        "    return similar_words\n",
        "\n",
        "# Find the most similar words to \"movie\" excluding \"movie\" using GloVe embeddings\n",
        "similar_words_glove_exclude_movie = most_similar_words_glove(\"movie\", exclude_word=\"movie\", top_n=5)\n",
        "print(f\"The most similar words to 'movie' (excluding 'movie') are: {similar_words_glove_exclude_movie}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5Rz0hoe38iK",
        "outputId": "f5ab4244-0956-461d-b5c7-36fef8a8dada"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar words to 'movie' (excluding 'movie') are: [('film', 0.85887855), ('tourism', 0.84934735), ('approach', 0.79086804), ('jail', 0.67923284), ('calif.', 0.6750692)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Glove Embeddings** => The most similar words to 'movie' (excluding 'movie') are: [('**film**', 0.85887855), ('**tourism**', 0.84934735), ('**approach**', 0.79086804), ('**jail**', 0.67923284), ('**calif.**', 0.6750692)]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Dcn1EgqZ6tw4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **With Word2Vec Model**"
      ],
      "metadata": {
        "id": "ryshfdyR7G0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Word2Vec model\n",
        "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Function to find most similar words (excluding a specified word)\n",
        "def most_similar_words_exclude(word, model, exclude_word, topn=5):\n",
        "    similar_words = model.most_similar(word, topn=topn + 1)  # Get one extra word\n",
        "    similar_words = [(w, s) for w, s in similar_words if w != exclude_word][:topn]\n",
        "    return similar_words\n",
        "\n",
        "# Find the most similar words to 'movie' excluding 'movie'\n",
        "similar_words_movie_exclude_movie = most_similar_words_exclude('movie', word2vec_model, exclude_word='movie')\n",
        "\n",
        "print(f\"The most similar words to 'movie' (excluding 'movie') are: {similar_words_movie_exclude_movie}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmG5DvwR6Qhw",
        "outputId": "1f2cadff-af53-4cdd-dd89-731d897144c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most similar words to 'movie' (excluding 'movie') are: [('film', 0.8676770329475403), ('movies', 0.8013108372688293), ('films', 0.7363011837005615), ('moive', 0.6830360889434814), ('Movie', 0.6693680286407471)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Word2Vec embeddings** => The most similar words to 'movie' (excluding 'movie') are: [('**film**', 0.8676770329475403), ('**movies**', 0.8013108372688293), ('**films**', 0.7363011837005615), ('**moive**', 0.6830360889434814), ('**Movie**', 0.6693680286407471)]"
      ],
      "metadata": {
        "id": "4KlAfpyQ7PAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem 2: One Step Ahead Forecasting - Moby Dick Chapter 4**"
      ],
      "metadata": {
        "id": "Sc43VZgkcwKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install contractions"
      ],
      "metadata": {
        "id": "v_ZMNJTgtsop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43c50c5a-9959-4aeb-cc7b-d196076de291"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.10/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.10/dist-packages (from textsearch>=0.0.21->contractions) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "with open('/content/drive/MyDrive/DeepLearning/HW/HW4/mobydick_ch04.txt', 'r', encoding='utf-8') as file:\n",
        "    text = file.read()"
      ],
      "metadata": {
        "id": "UE55CTF9IC8I"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text[:502]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "Bnaef0V7tLUA",
        "outputId": "dc375383-7f1e-4f8f-effa-e598ba82f937"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Call me Ishmael.  Some years ago--never mind how long\\nprecisely--having little or no money in my purse, and nothing\\nparticular to interest me on shore, I thought I would sail about a\\nlittle and see the watery part of the world.  It is a way I have of\\ndriving off the spleen and regulating the circulation.  Whenever I\\nfind myself growing grim about the mouth; whenever it is a damp,\\ndrizzly November in my soul; whenever I find myself involuntarily\\npausing before coffin warehouses, and bringing up the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem 2: 1.  Perform Text Preprocessing**\n",
        "\n",
        "*   Tokenization\n",
        "*   Convert to lower case\n",
        "*   Expand contraction\n",
        "*   Remove punctuation\n",
        "*   Lemmatization\n"
      ],
      "metadata": {
        "id": "Ck1x_dIfgZPx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Text preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # Expand contractions\n",
        "    # Example: {'isn't': 'is not', 'haven't': 'have not', ...}\n",
        "    tokens = [contractions.fix(word) for word in tokens]\n",
        "\n",
        "    # Remove punctuation except for newline character\n",
        "    # Remove punctuation except for newline character\n",
        "    punctuation_except_newline = string.punctuation.replace('\\n', '')\n",
        "    tokens = [word if word == '\\n' or word.strip(punctuation_except_newline + \"'\") else '\\n' for word in tokens]\n",
        "\n",
        "    # Lemmatization (using WordNet lemmatizer from NLTK)\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "start = time.time()\n",
        "# Apply preprocessing\n",
        "tokens = preprocess_text(text)\n",
        "stop = time.time()\n",
        "print(f'Cleaning took: {round((stop-start)/60, 3)} minutes')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY9gR3a3IC4u",
        "outputId": "a4eac6b6-e21f-4ba8-9fab-11ac2cce2b86"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaning took: 0.002 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:493]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "hVA-khMFSV7P",
        "outputId": "0156084a-8fe7-4281-b55a-a6f7dff52a59"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'call me ishmael \\n some year ago \\n never mind how long precisely \\n having little or no money in my purse \\n and nothing particular to interest me on shore \\n i thought i would sail about a little and see the watery part of the world \\n it is a way i have of driving off the spleen and regulating the circulation \\n whenever i find myself growing grim about the mouth \\n whenever it is a damp \\n drizzly november in my soul \\n whenever i find myself involuntarily pausing before coffin warehouse \\n and '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem 2: Q2. Keras Embedding Next Word Forecaster**"
      ],
      "metadata": {
        "id": "Lt_tOY7XWomu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehgik50Wu3rh",
        "outputId": "148a8882-3d56-446c-c485-cf69349520cf"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "61614"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[:980]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "rTTAd5XFvE8c",
        "outputId": "37176369-7441-4ca3-8ca0-f39c15b86252"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Call me Ishmael.  Some years ago--never mind how long\\nprecisely--having little or no money in my purse, and nothing\\nparticular to interest me on shore, I thought I would sail about a\\nlittle and see the watery part of the world.  It is a way I have of\\ndriving off the spleen and regulating the circulation.  Whenever I\\nfind myself growing grim about the mouth; whenever it is a damp,\\ndrizzly November in my soul; whenever I find myself involuntarily\\npausing before coffin warehouses, and bringing up the rear of every\\nfuneral I meet; and especially whenever my hypos get such an upper\\nhand of me, that it requires a strong moral principle to prevent me\\nfrom deliberately stepping into the street, and methodically knocking\\npeople's hats off--then, I account it high time to get to sea as soon\\nas I can.  This is my substitute for pistol and ball.  With a\\nphilosophical flourish Cato throws himself upon his sword; I quietly\\ntake to the ship.  There is nothing surprising in this.  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the entire cleaned text\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([tokens])\n",
        "total_words = len(tokenizer.word_index) + 1\n"
      ],
      "metadata": {
        "id": "opc3mVANvE5K"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38-gQUbfvE2g",
        "outputId": "0ccfe245-4da9-4217-82cd-1668a2886a03"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 1,\n",
              " 'a': 2,\n",
              " 'and': 3,\n",
              " 'of': 4,\n",
              " 'i': 5,\n",
              " 'to': 6,\n",
              " 'in': 7,\n",
              " 'it': 8,\n",
              " 'that': 9,\n",
              " 'his': 10,\n",
              " 'he': 11,\n",
              " 'was': 12,\n",
              " 'but': 13,\n",
              " 'me': 14,\n",
              " 'with': 15,\n",
              " 'as': 16,\n",
              " 'this': 17,\n",
              " 'at': 18,\n",
              " 'you': 19,\n",
              " 'is': 20,\n",
              " 'all': 21,\n",
              " 'my': 22,\n",
              " 'for': 23,\n",
              " 'on': 24,\n",
              " 'be': 25,\n",
              " 'from': 26,\n",
              " 'not': 27,\n",
              " 'there': 28,\n",
              " 'one': 29,\n",
              " 'up': 30,\n",
              " 'what': 31,\n",
              " 'him': 32,\n",
              " 'so': 33,\n",
              " 'bed': 34,\n",
              " 'no': 35,\n",
              " 'now': 36,\n",
              " 'about': 37,\n",
              " 'into': 38,\n",
              " 'or': 39,\n",
              " 'by': 40,\n",
              " 'were': 41,\n",
              " 'out': 42,\n",
              " 'had': 43,\n",
              " 'then': 44,\n",
              " 'harpooneer': 45,\n",
              " 'have': 46,\n",
              " 'an': 47,\n",
              " 'some': 48,\n",
              " 'little': 49,\n",
              " 'upon': 50,\n",
              " 'like': 51,\n",
              " 'old': 52,\n",
              " 'if': 53,\n",
              " 'they': 54,\n",
              " 'over': 55,\n",
              " 'landlord': 56,\n",
              " 'thought': 57,\n",
              " 'room': 58,\n",
              " 'would': 59,\n",
              " 'when': 60,\n",
              " 'here': 61,\n",
              " 'head': 62,\n",
              " 'night': 63,\n",
              " 'such': 64,\n",
              " 'which': 65,\n",
              " 'could': 66,\n",
              " 'sea': 67,\n",
              " 'though': 68,\n",
              " 'time': 69,\n",
              " 'do': 70,\n",
              " 'man': 71,\n",
              " 'said': 72,\n",
              " 'very': 73,\n",
              " 'go': 74,\n",
              " 'these': 75,\n",
              " 'more': 76,\n",
              " 'did': 77,\n",
              " 'first': 78,\n",
              " 'sort': 79,\n",
              " 'last': 80,\n",
              " 'never': 81,\n",
              " 'other': 82,\n",
              " 'down': 83,\n",
              " 'most': 84,\n",
              " 'been': 85,\n",
              " 'see': 86,\n",
              " 'your': 87,\n",
              " 'them': 88,\n",
              " 'must': 89,\n",
              " 'tell': 90,\n",
              " 'much': 91,\n",
              " 'good': 92,\n",
              " 'off': 93,\n",
              " 'myself': 94,\n",
              " 'are': 95,\n",
              " 'yet': 96,\n",
              " 'sleep': 97,\n",
              " 'who': 98,\n",
              " 'seemed': 99,\n",
              " 'light': 100,\n",
              " 'long': 101,\n",
              " 'way': 102,\n",
              " 'their': 103,\n",
              " 'just': 104,\n",
              " 'great': 105,\n",
              " 'being': 106,\n",
              " 'than': 107,\n",
              " 'place': 108,\n",
              " \"it's\": 109,\n",
              " 'queequeg': 110,\n",
              " 'before': 111,\n",
              " 'get': 112,\n",
              " 'round': 113,\n",
              " 'still': 114,\n",
              " 'any': 115,\n",
              " 'too': 116,\n",
              " 'only': 117,\n",
              " 'door': 118,\n",
              " 'how': 119,\n",
              " 'himself': 120,\n",
              " 'where': 121,\n",
              " 'heads': 122,\n",
              " 'come': 123,\n",
              " 'ever': 124,\n",
              " 'two': 125,\n",
              " 'enough': 126,\n",
              " 'made': 127,\n",
              " 'hand': 128,\n",
              " 'same': 129,\n",
              " 'looking': 130,\n",
              " 'something': 131,\n",
              " 'may': 132,\n",
              " 'nothing': 133,\n",
              " 'almost': 134,\n",
              " 'say': 135,\n",
              " 'should': 136,\n",
              " 'side': 137,\n",
              " 'why': 138,\n",
              " 'own': 139,\n",
              " 'new': 140,\n",
              " 'again': 141,\n",
              " 'came': 142,\n",
              " 'arm': 143,\n",
              " 'house': 144,\n",
              " 'away': 145,\n",
              " 'might': 146,\n",
              " 'can': 147,\n",
              " 'take': 148,\n",
              " 'towards': 149,\n",
              " 'water': 150,\n",
              " 'will': 151,\n",
              " 'under': 152,\n",
              " 'going': 153,\n",
              " 'we': 154,\n",
              " 'rather': 155,\n",
              " 'make': 156,\n",
              " 'stood': 157,\n",
              " 'boots': 158,\n",
              " 'ye': 159,\n",
              " 'back': 160,\n",
              " 'tomahawk': 161,\n",
              " 'part': 162,\n",
              " 'soon': 163,\n",
              " 'against': 164,\n",
              " 'those': 165,\n",
              " \"don't\": 166,\n",
              " 'between': 167,\n",
              " 'after': 168,\n",
              " 'whaling': 169,\n",
              " 'lay': 170,\n",
              " 'took': 171,\n",
              " 'half': 172,\n",
              " 'began': 173,\n",
              " 'face': 174,\n",
              " 'world': 175,\n",
              " 'streets': 176,\n",
              " 'land': 177,\n",
              " 'better': 178,\n",
              " 'once': 179,\n",
              " 'voyage': 180,\n",
              " 'give': 181,\n",
              " 'well': 182,\n",
              " 'however': 183,\n",
              " 'else': 184,\n",
              " 'heard': 185,\n",
              " 'put': 186,\n",
              " 'stop': 187,\n",
              " 'dark': 188,\n",
              " 'went': 189,\n",
              " 'black': 190,\n",
              " 'window': 191,\n",
              " 'cannibal': 192,\n",
              " 'fire': 193,\n",
              " 'mind': 194,\n",
              " 'every': 195,\n",
              " 'ship': 196,\n",
              " 'town': 197,\n",
              " 'stand': 198,\n",
              " 'strange': 199,\n",
              " 'without': 200,\n",
              " 'feet': 201,\n",
              " 'whether': 202,\n",
              " 'because': 203,\n",
              " 'eyes': 204,\n",
              " 'think': 205,\n",
              " 'thinks': 206,\n",
              " 'idea': 207,\n",
              " 'whale': 208,\n",
              " 'nantucket': 209,\n",
              " 'late': 210,\n",
              " 'cold': 211,\n",
              " 'our': 212,\n",
              " 'found': 213,\n",
              " 'full': 214,\n",
              " 'morning': 215,\n",
              " 'sleeping': 216,\n",
              " 'feeling': 217,\n",
              " 'got': 218,\n",
              " \"he's\": 219,\n",
              " 'ishmael': 220,\n",
              " 'having': 221,\n",
              " 'particular': 222,\n",
              " 'her': 223,\n",
              " 'right': 224,\n",
              " 'its': 225,\n",
              " 'look': 226,\n",
              " 'south': 227,\n",
              " 'does': 228,\n",
              " 'let': 229,\n",
              " 'set': 230,\n",
              " 'yourself': 231,\n",
              " 'image': 232,\n",
              " 'saw': 233,\n",
              " 'am': 234,\n",
              " 'besides': 235,\n",
              " 'sailor': 236,\n",
              " 'seas': 237,\n",
              " 'rolled': 238,\n",
              " 'bag': 239,\n",
              " 'till': 240,\n",
              " 'harpoon': 241,\n",
              " 'day': 242,\n",
              " 'sign': 243,\n",
              " 'looked': 244,\n",
              " 'hard': 245,\n",
              " 'moment': 246,\n",
              " 'corner': 247,\n",
              " 'entry': 248,\n",
              " 'four': 249,\n",
              " 'wall': 250,\n",
              " 'table': 251,\n",
              " 'indeed': 252,\n",
              " 'bench': 253,\n",
              " 'chest': 254,\n",
              " 'while': 255,\n",
              " 'stranger': 256,\n",
              " \"i'll\": 257,\n",
              " 'possible': 258,\n",
              " 'floor': 259,\n",
              " 'squares': 260,\n",
              " 'hat': 261,\n",
              " 'money': 262,\n",
              " 'whenever': 263,\n",
              " 'mouth': 264,\n",
              " 'coffin': 265,\n",
              " 'high': 266,\n",
              " 'knew': 267,\n",
              " 'men': 268,\n",
              " 'hours': 269,\n",
              " 'green': 270,\n",
              " 'bit': 271,\n",
              " 'within': 272,\n",
              " 'told': 273,\n",
              " 'story': 274,\n",
              " 'mean': 275,\n",
              " 'thing': 276,\n",
              " 'speak': 277,\n",
              " 'order': 278,\n",
              " 'making': 279,\n",
              " 'even': 280,\n",
              " 'perhaps': 281,\n",
              " 'things': 282,\n",
              " 'answer': 283,\n",
              " 'parts': 284,\n",
              " 'wild': 285,\n",
              " 'reason': 286,\n",
              " 'young': 287,\n",
              " 'business': 288,\n",
              " 'dead': 289,\n",
              " 'another': 290,\n",
              " 'middle': 291,\n",
              " 'sure': 292,\n",
              " 'candle': 293,\n",
              " 'presently': 294,\n",
              " 'low': 295,\n",
              " 'turned': 296,\n",
              " 'teeth': 297,\n",
              " 'dim': 298,\n",
              " 'euroclydon': 299,\n",
              " 'kept': 300,\n",
              " 'glass': 301,\n",
              " 'afterwards': 302,\n",
              " 'large': 303,\n",
              " 'three': 304,\n",
              " 'through': 305,\n",
              " 'savage': 306,\n",
              " 'telling': 307,\n",
              " 'getting': 308,\n",
              " 'small': 309,\n",
              " 'next': 310,\n",
              " 'seeing': 311,\n",
              " 'sell': 312,\n",
              " 'felt': 313,\n",
              " 'e': 314,\n",
              " 'years': 315,\n",
              " 'ago': 316,\n",
              " 'sail': 317,\n",
              " 'especially': 318,\n",
              " 'street': 319,\n",
              " 'city': 320,\n",
              " 'few': 321,\n",
              " 'previous': 322,\n",
              " 'sight': 323,\n",
              " 'straight': 324,\n",
              " 'nigh': 325,\n",
              " 'legs': 326,\n",
              " 'try': 327,\n",
              " 'yes': 328,\n",
              " 'picture': 329,\n",
              " 'unless': 330,\n",
              " 'poor': 331,\n",
              " 'coat': 332,\n",
              " 'passenger': 333,\n",
              " 'taking': 334,\n",
              " 'true': 335,\n",
              " 'always': 336,\n",
              " 'us': 337,\n",
              " 'really': 338,\n",
              " 'marvellous': 339,\n",
              " 'air': 340,\n",
              " 'far': 341,\n",
              " 'second': 342,\n",
              " 'many': 343,\n",
              " 'has': 344,\n",
              " 'unaccountable': 345,\n",
              " 'grand': 346,\n",
              " 'jolly': 347,\n",
              " 'open': 348,\n",
              " 'shirt': 349,\n",
              " 'cape': 350,\n",
              " 'bedford': 351,\n",
              " 'craft': 352,\n",
              " 'fine': 353,\n",
              " 'further': 354,\n",
              " 'fish': 355,\n",
              " 'inn': 356,\n",
              " 'ice': 357,\n",
              " 'frost': 358,\n",
              " 'foot': 359,\n",
              " 'wide': 360,\n",
              " 'white': 361,\n",
              " 'tall': 362,\n",
              " 'spouter': 363,\n",
              " 'wooden': 364,\n",
              " 'worse': 365,\n",
              " 'death': 366,\n",
              " 'mine': 367,\n",
              " \"didn't\": 368,\n",
              " 'lazarus': 369,\n",
              " 'keep': 370,\n",
              " 'along': 371,\n",
              " 'hung': 372,\n",
              " 'throwing': 373,\n",
              " 'centre': 374,\n",
              " 'rest': 375,\n",
              " 'fact': 376,\n",
              " 'hair': 377,\n",
              " 'broken': 378,\n",
              " 'kill': 379,\n",
              " 'chimney': 380,\n",
              " 'fancy': 381,\n",
              " 'bar': 382,\n",
              " 'supper': 383,\n",
              " 'trying': 384,\n",
              " 'dumplings': 385,\n",
              " 'heavens': 386,\n",
              " 'manner': 387,\n",
              " 'devil': 388,\n",
              " 'together': 389,\n",
              " \"that's\": 390,\n",
              " 'seen': 391,\n",
              " 'deal': 392,\n",
              " 'know': 393,\n",
              " 'skin': 394,\n",
              " 'shavings': 395,\n",
              " 'peddling': 396,\n",
              " 'sunday': 397,\n",
              " 'counterpane': 398,\n",
              " 'mat': 399,\n",
              " 'christian': 400,\n",
              " 'commenced': 401,\n",
              " 'thinking': 402,\n",
              " 'similar': 403,\n",
              " 'sun': 404,\n",
              " 'afraid': 405,\n",
              " 'length': 406,\n",
              " 'idol': 407,\n",
              " 'sabbee': 408,\n",
              " 'waking': 409,\n",
              " 'purse': 410,\n",
              " 'find': 411,\n",
              " 'damp': 412,\n",
              " 'soul': 413,\n",
              " 'strong': 414,\n",
              " 'account': 415,\n",
              " 'sword': 416,\n",
              " 'quietly': 417,\n",
              " 'degree': 418,\n",
              " 'left': 419,\n",
              " 'around': 420,\n",
              " 'fixed': 421,\n",
              " 'ships': 422,\n",
              " 'days': 423,\n",
              " 'miles': 424,\n",
              " 'country': 425,\n",
              " 'stream': 426,\n",
              " 'lead': 427,\n",
              " 'american': 428,\n",
              " 'each': 429,\n",
              " 'goes': 430,\n",
              " 'deep': 431,\n",
              " 'distant': 432,\n",
              " 'winds': 433,\n",
              " 'blue': 434,\n",
              " 'among': 435,\n",
              " 'suddenly': 436,\n",
              " 'feel': 437,\n",
              " 'meaning': 438,\n",
              " 'phantom': 439,\n",
              " 'life': 440,\n",
              " 'passengers': 441,\n",
              " 'nor': 442,\n",
              " 'cook': 443,\n",
              " 'kind': 444,\n",
              " 'quite': 445,\n",
              " 'care': 446,\n",
              " 'board': 447,\n",
              " 'somehow': 448,\n",
              " 'broiled': 449,\n",
              " 'mast': 450,\n",
              " 'sense': 451,\n",
              " \"ain't\": 452,\n",
              " 'knowing': 453,\n",
              " 'either': 454,\n",
              " 'passed': 455,\n",
              " 'hands': 456,\n",
              " 'paying': 457,\n",
              " 'pay': 458,\n",
              " 'penny': 459,\n",
              " 'heaven': 460,\n",
              " 'sailors': 461,\n",
              " 'cannot': 462,\n",
              " 'exactly': 463,\n",
              " 'short': 464,\n",
              " 'easy': 465,\n",
              " 'portentous': 466,\n",
              " 'island': 467,\n",
              " 'nameless': 468,\n",
              " 'sounds': 469,\n",
              " 'since': 470,\n",
              " 'snow': 471,\n",
              " 'saturday': 472,\n",
              " 'matter': 473,\n",
              " 'red': 474,\n",
              " 'partly': 475,\n",
              " 'ere': 476,\n",
              " 'became': 477,\n",
              " 'meanwhile': 478,\n",
              " 'pocket': 479,\n",
              " 'darkness': 480,\n",
              " 'harpoons': 481,\n",
              " 'watch': 482,\n",
              " 'broad': 483,\n",
              " 'entering': 484,\n",
              " 'ha': 485,\n",
              " 'ashes': 486,\n",
              " 'opened': 487,\n",
              " 'peter': 488,\n",
              " 'name': 489,\n",
              " 'suppose': 490,\n",
              " 'quiet': 491,\n",
              " 'best': 492,\n",
              " 'tempestuous': 493,\n",
              " 'says': 494,\n",
              " 'thou': 495,\n",
              " 'both': 496,\n",
              " 'occurred': 497,\n",
              " 'dives': 498,\n",
              " 'holding': 499,\n",
              " 'frozen': 500,\n",
              " 'plenty': 501,\n",
              " 'altogether': 502,\n",
              " 'plain': 503,\n",
              " 'whom': 504,\n",
              " 'clean': 505,\n",
              " 'human': 506,\n",
              " 'entered': 507,\n",
              " 'wrinkled': 508,\n",
              " 'shelf': 509,\n",
              " \"whale's\": 510,\n",
              " 'jonah': 511,\n",
              " \"harpooneer's\": 512,\n",
              " 'blanket': 513,\n",
              " \"goin'\": 514,\n",
              " 'bitter': 515,\n",
              " 'sat': 516,\n",
              " 'settle': 517,\n",
              " \"couldn't\": 518,\n",
              " 'monkey': 519,\n",
              " 'chap': 520,\n",
              " 'help': 521,\n",
              " 'spend': 522,\n",
              " 'landed': 523,\n",
              " 'standing': 524,\n",
              " 'held': 525,\n",
              " 'somewhat': 526,\n",
              " 'sober': 527,\n",
              " 'whole': 528,\n",
              " 'dam': 529,\n",
              " 'brown': 530,\n",
              " 'bulkington': 531,\n",
              " \"o'clock\": 532,\n",
              " 'none': 533,\n",
              " 'coming': 534,\n",
              " \"i've\": 535,\n",
              " 'wait': 536,\n",
              " 'plane': 537,\n",
              " 'saying': 538,\n",
              " 'grinning': 539,\n",
              " 'placed': 540,\n",
              " \"can't\": 541,\n",
              " 'shouted': 542,\n",
              " 'broke': 543,\n",
              " 'bedfellow': 544,\n",
              " 'zealand': 545,\n",
              " 'sal': 546,\n",
              " \"won't\": 547,\n",
              " 'wash': 548,\n",
              " 'thrown': 549,\n",
              " 'purplish': 550,\n",
              " 'turn': 551,\n",
              " 'completely': 552,\n",
              " 'fear': 553,\n",
              " 'grego': 554,\n",
              " 'baby': 555,\n",
              " 'slowly': 556,\n",
              " 'civilized': 557,\n",
              " 'call': 558,\n",
              " 'precisely': 559,\n",
              " 'involuntarily': 560,\n",
              " 'pausing': 561,\n",
              " 'warehouses': 562,\n",
              " 'requires': 563,\n",
              " 'nearly': 564,\n",
              " 'ocean': 565,\n",
              " 'indian': 566,\n",
              " 'waterward': 567,\n",
              " 'battery': 568,\n",
              " 'noble': 569,\n",
              " 'washed': 570,\n",
              " 'crowds': 571,\n",
              " 'sabbath': 572,\n",
              " 'afternoon': 573,\n",
              " 'thence': 574,\n",
              " 'silent': 575,\n",
              " 'thousands': 576,\n",
              " 'reveries': 577,\n",
              " 'leaning': 578,\n",
              " 'seated': 579,\n",
              " 'bulwarks': 580,\n",
              " 'aloft': 581,\n",
              " 'week': 582,\n",
              " 'plaster': 583,\n",
              " 'gone': 584,\n",
              " 'bound': 585,\n",
              " 'content': 586,\n",
              " 'yonder': 587,\n",
              " 'falling': 588,\n",
              " 'north': 589,\n",
              " 'please': 590,\n",
              " 'ten': 591,\n",
              " 'leaves': 592,\n",
              " 'magic': 593,\n",
              " 'plunged': 594,\n",
              " 'metaphysical': 595,\n",
              " 'artist': 596,\n",
              " 'chief': 597,\n",
              " 'trunk': 598,\n",
              " 'meadow': 599,\n",
              " 'smoke': 600,\n",
              " 'reaching': 601,\n",
              " 'hill': 602,\n",
              " 'thus': 603,\n",
              " 'pine': 604,\n",
              " 'sighs': 605,\n",
              " \"shepherd's\": 606,\n",
              " 'june': 607,\n",
              " 'scores': 608,\n",
              " 'thousand': 609,\n",
              " 'silver': 610,\n",
              " 'sadly': 611,\n",
              " 'robust': 612,\n",
              " 'healthy': 613,\n",
              " 'boy': 614,\n",
              " 'crazy': 615,\n",
              " 'hold': 616,\n",
              " 'holy': 617,\n",
              " 'brother': 618,\n",
              " 'ourselves': 619,\n",
              " 'begin': 620,\n",
              " 'grow': 621,\n",
              " 'inferred': 622,\n",
              " 'needs': 623,\n",
              " 'themselves': 624,\n",
              " 'commodore': 625,\n",
              " 'captain': 626,\n",
              " 'glory': 627,\n",
              " 'whatsoever': 628,\n",
              " 'confess': 629,\n",
              " 'officer': 630,\n",
              " 'respectfully': 631,\n",
              " 'horse': 632,\n",
              " 'huge': 633,\n",
              " 'houses': 634,\n",
              " 'forecastle': 635,\n",
              " 'jump': 636,\n",
              " 'spar': 637,\n",
              " 'particularly': 638,\n",
              " 'putting': 639,\n",
              " 'tar': 640,\n",
              " 'schoolmaster': 641,\n",
              " 'boys': 642,\n",
              " 'transition': 643,\n",
              " 'grin': 644,\n",
              " 'bear': 645,\n",
              " 'hunks': 646,\n",
              " 'sweep': 647,\n",
              " 'weighed': 648,\n",
              " 'anything': 649,\n",
              " 'less': 650,\n",
              " 'thump': 651,\n",
              " 'point': 652,\n",
              " 'view': 653,\n",
              " 'single': 654,\n",
              " 'difference': 655,\n",
              " 'paid': 656,\n",
              " 'act': 657,\n",
              " 'uncomfortable': 658,\n",
              " 'compare': 659,\n",
              " 'earthly': 660,\n",
              " 'enter': 661,\n",
              " 'deck': 662,\n",
              " 'quarter': 663,\n",
              " 'leaders': 664,\n",
              " 'smelt': 665,\n",
              " 'fates': 666,\n",
              " 'doubtless': 667,\n",
              " 'formed': 668,\n",
              " 'run': 669,\n",
              " 'stage': 670,\n",
              " 'shabby': 671,\n",
              " 'others': 672,\n",
              " 'circumstances': 673,\n",
              " 'motives': 674,\n",
              " 'various': 675,\n",
              " 'mysterious': 676,\n",
              " 'curiosity': 677,\n",
              " 'tormented': 678,\n",
              " 'everlasting': 679,\n",
              " 'wonder': 680,\n",
              " 'purpose': 681,\n",
              " 'floated': 682,\n",
              " 'stuffed': 683,\n",
              " 'horn': 684,\n",
              " 'arrived': 685,\n",
              " 'offer': 686,\n",
              " 'following': 687,\n",
              " 'embark': 688,\n",
              " 'pleased': 689,\n",
              " 'original': 690,\n",
              " 'stranded': 691,\n",
              " 'leviathan': 692,\n",
              " 'whales': 693,\n",
              " 'nay': 694,\n",
              " 'dismal': 695,\n",
              " 'wherever': 696,\n",
              " 'dreary': 697,\n",
              " 'crossed': 698,\n",
              " 'expensive': 699,\n",
              " 'bright': 700,\n",
              " 'windows': 701,\n",
              " 'packed': 702,\n",
              " 'inches': 703,\n",
              " 'thick': 704,\n",
              " 'hear': 705,\n",
              " 'tinkling': 706,\n",
              " 'glasses': 707,\n",
              " 'blackness': 708,\n",
              " 'moving': 709,\n",
              " 'hour': 710,\n",
              " 'proved': 711,\n",
              " 'meant': 712,\n",
              " 'public': 713,\n",
              " 'box': 714,\n",
              " 'flying': 715,\n",
              " 'trap': 716,\n",
              " 'loud': 717,\n",
              " 'voice': 718,\n",
              " 'sitting': 719,\n",
              " 'beyond': 720,\n",
              " 'negro': 721,\n",
              " 'creaking': 722,\n",
              " 'swinging': 723,\n",
              " 'painting': 724,\n",
              " 'representing': 725,\n",
              " 'connexion': 726,\n",
              " 'itself': 727,\n",
              " 'carted': 728,\n",
              " 'burnt': 729,\n",
              " 'spot': 730,\n",
              " 'queer': 731,\n",
              " 'gable': 732,\n",
              " 'ended': 733,\n",
              " 'sharp': 734,\n",
              " 'wind': 735,\n",
              " 'howling': 736,\n",
              " 'nevertheless': 737,\n",
              " 'called': 738,\n",
              " 'outside': 739,\n",
              " 'passage': 740,\n",
              " 'body': 741,\n",
              " 'curbstone': 742,\n",
              " 'corn': 743,\n",
              " 'pooh': 744,\n",
              " 'northern': 745,\n",
              " 'lights': 746,\n",
              " 'summer': 747,\n",
              " 'lengthwise': 748,\n",
              " 'gods': 749,\n",
              " 'lie': 750,\n",
              " 'study': 751,\n",
              " 'series': 752,\n",
              " 'arrive': 753,\n",
              " 'shadows': 754,\n",
              " 'dint': 755,\n",
              " 'conclusion': 756,\n",
              " 'confounded': 757,\n",
              " 'limber': 758,\n",
              " 'truly': 759,\n",
              " 'drive': 760,\n",
              " 'unimaginable': 761,\n",
              " 'midnight': 762,\n",
              " 'unnatural': 763,\n",
              " 'breaking': 764,\n",
              " 'design': 765,\n",
              " 'opposite': 766,\n",
              " 'monstrous': 767,\n",
              " 'knots': 768,\n",
              " 'vast': 769,\n",
              " 'handle': 770,\n",
              " 'wondered': 771,\n",
              " 'mixed': 772,\n",
              " 'deformed': 773,\n",
              " 'flung': 774,\n",
              " 'iron': 775,\n",
              " 'arched': 776,\n",
              " 'cut': 777,\n",
              " 'times': 778,\n",
              " 'beneath': 779,\n",
              " 'covered': 780,\n",
              " 'gathered': 781,\n",
              " 'stands': 782,\n",
              " 'rude': 783,\n",
              " 'bone': 784,\n",
              " 'abominable': 785,\n",
              " 'measure': 786,\n",
              " 'seamen': 787,\n",
              " 'skrimshander': 788,\n",
              " 'sought': 789,\n",
              " 'added': 790,\n",
              " 'forehead': 791,\n",
              " 'objections': 792,\n",
              " \"you'd\": 793,\n",
              " 'used': 794,\n",
              " 'depend': 795,\n",
              " 'decent': 796,\n",
              " \"man's\": 797,\n",
              " 'want': 798,\n",
              " 'ready': 799,\n",
              " 'working': 800,\n",
              " 'space': 801,\n",
              " 'lips': 802,\n",
              " 'fingers': 803,\n",
              " 'fare': 804,\n",
              " 'fellow': 805,\n",
              " \"you'll\": 806,\n",
              " 'nightmare': 807,\n",
              " 'complexioned': 808,\n",
              " 'eats': 809,\n",
              " \"'em\": 810,\n",
              " 'afore': 811,\n",
              " 'resolved': 812,\n",
              " 'noise': 813,\n",
              " 'offing': 814,\n",
              " \"years'\": 815,\n",
              " 'shaggy': 816,\n",
              " 'woollen': 817,\n",
              " 'stiff': 818,\n",
              " 'labrador': 819,\n",
              " 'wake': 820,\n",
              " 'bad': 821,\n",
              " 'mounted': 822,\n",
              " 'generally': 823,\n",
              " 'shipmates': 824,\n",
              " 'become': 825,\n",
              " 'height': 826,\n",
              " 'seem': 827,\n",
              " 'plan': 828,\n",
              " 'private': 829,\n",
              " 'unknown': 830,\n",
              " 'apartment': 831,\n",
              " 'hammock': 832,\n",
              " 'linen': 833,\n",
              " 'home': 834,\n",
              " 'hole': 835,\n",
              " \"i'm\": 836,\n",
              " 'mattress': 837,\n",
              " 'planing': 838,\n",
              " 'knot': 839,\n",
              " 'near': 840,\n",
              " 'sake': 841,\n",
              " 'chair': 842,\n",
              " 'narrow': 843,\n",
              " 'leaving': 844,\n",
              " 'interval': 845,\n",
              " 'met': 846,\n",
              " 'inside': 847,\n",
              " 'violent': 848,\n",
              " \"there's\": 849,\n",
              " 'ones': 850,\n",
              " 'comprehension': 851,\n",
              " 'bird': 852,\n",
              " 'airley': 853,\n",
              " 'airth': 854,\n",
              " 'engaged': 855,\n",
              " 'whittling': 856,\n",
              " 'guess': 857,\n",
              " 'done': 858,\n",
              " 'break': 859,\n",
              " 'understand': 860,\n",
              " 'certain': 861,\n",
              " 'demand': 862,\n",
              " 'selling': 863,\n",
              " 'sir': 864,\n",
              " 'string': 865,\n",
              " 'mystery': 866,\n",
              " 'showed': 867,\n",
              " 'dangerous': 868,\n",
              " 'flukes': 869,\n",
              " 'slept': 870,\n",
              " 'big': 871,\n",
              " 'sam': 872,\n",
              " \"wouldn't\": 873,\n",
              " 'lighted': 874,\n",
              " 'stairs': 875,\n",
              " 'placing': 876,\n",
              " 'double': 877,\n",
              " 'eyeing': 878,\n",
              " 'belonging': 879,\n",
              " 'papered': 880,\n",
              " 'parcel': 881,\n",
              " 'tried': 882,\n",
              " 'satisfactory': 883,\n",
              " 'concerning': 884,\n",
              " 'edges': 885,\n",
              " 'stuck': 886,\n",
              " 'gave': 887,\n",
              " 'neck': 888,\n",
              " 'jacket': 889,\n",
              " 'sleeves': 890,\n",
              " 'undressed': 891,\n",
              " 'remembering': 892,\n",
              " 'jumped': 893,\n",
              " 'pantaloons': 894,\n",
              " 'blowing': 895,\n",
              " 'doze': 896,\n",
              " 'pretty': 897,\n",
              " 'heavy': 898,\n",
              " 'save': 899,\n",
              " 'infernal': 900,\n",
              " 'peddler': 901,\n",
              " 'yellow': 902,\n",
              " 'colour': 903,\n",
              " 'dreadfully': 904,\n",
              " 'sticking': 905,\n",
              " 'cheeks': 906,\n",
              " 'truth': 907,\n",
              " 'remembered': 908,\n",
              " 'whaleman': 909,\n",
              " 'tattooed': 910,\n",
              " 'concluded': 911,\n",
              " 'lying': 912,\n",
              " 'tanning': 913,\n",
              " 'hot': 914,\n",
              " 'produced': 915,\n",
              " 'beaver': 916,\n",
              " 'singing': 917,\n",
              " 'bolted': 918,\n",
              " 'arms': 919,\n",
              " 'running': 920,\n",
              " 'curious': 921,\n",
              " 'hunch': 922,\n",
              " 'congo': 923,\n",
              " 'ill': 924,\n",
              " 'takes': 925,\n",
              " 'biscuit': 926,\n",
              " 'top': 927,\n",
              " 'lamp': 928,\n",
              " 'succeeded': 929,\n",
              " 'polite': 930,\n",
              " 'guttural': 931,\n",
              " 'pagan': 932,\n",
              " 'spell': 933,\n",
              " 'tobacco': 934,\n",
              " 'grunt': 935,\n",
              " 'whatever': 936,\n",
              " 'ee': 937,\n",
              " 'horrid': 938,\n",
              " 'pipe': 939,\n",
              " 'smoking': 940,\n",
              " 'complied': 941,\n",
              " \"queequeg's\": 942,\n",
              " 'patchwork': 943,\n",
              " 'figure': 944,\n",
              " 'shade': 945,\n",
              " 'quilt': 946,\n",
              " 'hugging': 947,\n",
              " 'sensations': 948,\n",
              " 'explain': 949,\n",
              " 'remember': 950,\n",
              " 'circumstance': 951,\n",
              " 'reality': 952,\n",
              " 'stepmother': 953,\n",
              " 'sixteen': 954,\n",
              " 'abed': 955,\n",
              " 'troubled': 956,\n",
              " 'wrapped': 957,\n",
              " 'supernatural': 958,\n",
              " 'ages': 959,\n",
              " 'awful': 960,\n",
              " 'consciousness': 961,\n",
              " 'observing': 962,\n",
              " 'creature': 963,\n",
              " 'dress': 964,\n",
              " 'watching': 965,\n",
              " 'probably': 966,\n",
              " 'toilet': 967,\n",
              " 'interest': 968,\n",
              " 'shore': 969,\n",
              " 'watery': 970,\n",
              " 'driving': 971,\n",
              " 'spleen': 972,\n",
              " 'regulating': 973,\n",
              " 'circulation': 974,\n",
              " 'growing': 975,\n",
              " 'grim': 976,\n",
              " 'drizzly': 977,\n",
              " 'november': 978,\n",
              " 'bringing': 979,\n",
              " 'rear': 980,\n",
              " 'funeral': 981,\n",
              " 'meet': 982,\n",
              " 'hypos': 983,\n",
              " 'upper': 984,\n",
              " 'moral': 985,\n",
              " 'principle': 986,\n",
              " 'prevent': 987,\n",
              " 'deliberately': 988,\n",
              " 'stepping': 989,\n",
              " 'methodically': 990,\n",
              " 'knocking': 991,\n",
              " \"people's\": 992,\n",
              " 'hats': 993,\n",
              " 'substitute': 994,\n",
              " 'pistol': 995,\n",
              " 'ball': 996,\n",
              " 'philosophical': 997,\n",
              " 'flourish': 998,\n",
              " 'cato': 999,\n",
              " 'throws': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in tokens.split('\\n'):\n",
        "  #print(line)\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  #print(token_list)\n",
        "  for i in range(1, len(token_list)):\n",
        "      n_gram_sequence = token_list[:i+1]\n",
        "      #print(n_gram_sequence)\n",
        "      input_sequences.append(n_gram_sequence)\n",
        "      #print(input_sequence)"
      ],
      "metadata": {
        "id": "1vo_6zgSPo3r"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequence =  np.array(pad_sequences(input_sequences, maxlen = max_sequence_len, padding='pre' ))"
      ],
      "metadata": {
        "id": "BTfcxyIGvExI"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf7XNrAivEul",
        "outputId": "3f8031a1-fd09-4ee5-8d32-8181ccb55295"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0, ...,    0,  558,   14],\n",
              "       [   0,    0,    0, ...,  558,   14,  220],\n",
              "       [   0,    0,    0, ...,   14,  220,   48],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,  241,   51,    2],\n",
              "       [   0,    0,    0, ...,   51,    2, 2726],\n",
              "       [   0,    0,    0, ...,    2, 2726, 2727]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = input_sequence[:, :-1]\n",
        "y = input_sequence[:,-1]"
      ],
      "metadata": {
        "id": "g-fuo8eKvEr6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0eyPyWkvEpH",
        "outputId": "468d4e37-5fce-4054-f1be-6807069a633a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0,   0, 558], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJxIR-86vEkD",
        "outputId": "bae40e09-a428-40af-b2e3-baf31b9a2270"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99Flb6iQvEmr",
        "outputId": "b11ae777-4ca1-4309-84f9-d7572163de31"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         0, 558,  14], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_7w5IuJvEhm",
        "outputId": "5b02a55a-9ec1-4a6e-cab8-7998d88aa81b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  14,  220,   48, ...,    2, 2726, 2727], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(tf.keras.utils.to_categorical(y, num_classes= total_words))\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XYywJeuvEe_",
        "outputId": "c3052923-8e61-48eb-bf09-bf210a3451bb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=total_words, output_dim=100, input_length=max_sequence_len-1)) # using keras + LSTM\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHO749HyTlVY",
        "outputId": "d526b7b7-3a6f-4a90-e7b7-f8d475f6bea5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 16, 100)           272800    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 150)               150600    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2728)              411928    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 835328 (3.19 MB)\n",
            "Trainable params: 835328 (3.19 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X, y, epochs=50, verbose=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uGvVkQAT7EP",
        "outputId": "afcd6f09-68f8-41af-ed3b-f67600b786f0"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "322/322 - 8s - loss: 6.6320 - accuracy: 0.0497 - 8s/epoch - 26ms/step\n",
            "Epoch 2/50\n",
            "322/322 - 2s - loss: 6.1490 - accuracy: 0.0579 - 2s/epoch - 6ms/step\n",
            "Epoch 3/50\n",
            "322/322 - 2s - loss: 6.0056 - accuracy: 0.0681 - 2s/epoch - 5ms/step\n",
            "Epoch 4/50\n",
            "322/322 - 2s - loss: 5.8648 - accuracy: 0.0720 - 2s/epoch - 6ms/step\n",
            "Epoch 5/50\n",
            "322/322 - 2s - loss: 5.7112 - accuracy: 0.0828 - 2s/epoch - 6ms/step\n",
            "Epoch 6/50\n",
            "322/322 - 2s - loss: 5.5318 - accuracy: 0.0944 - 2s/epoch - 5ms/step\n",
            "Epoch 7/50\n",
            "322/322 - 1s - loss: 5.3400 - accuracy: 0.1063 - 1s/epoch - 4ms/step\n",
            "Epoch 8/50\n",
            "322/322 - 2s - loss: 5.1379 - accuracy: 0.1183 - 2s/epoch - 5ms/step\n",
            "Epoch 9/50\n",
            "322/322 - 1s - loss: 4.9264 - accuracy: 0.1338 - 1s/epoch - 4ms/step\n",
            "Epoch 10/50\n",
            "322/322 - 1s - loss: 4.7132 - accuracy: 0.1436 - 1s/epoch - 5ms/step\n",
            "Epoch 11/50\n",
            "322/322 - 1s - loss: 4.4986 - accuracy: 0.1595 - 1s/epoch - 5ms/step\n",
            "Epoch 12/50\n",
            "322/322 - 2s - loss: 4.2807 - accuracy: 0.1744 - 2s/epoch - 5ms/step\n",
            "Epoch 13/50\n",
            "322/322 - 2s - loss: 4.0656 - accuracy: 0.1970 - 2s/epoch - 5ms/step\n",
            "Epoch 14/50\n",
            "322/322 - 2s - loss: 3.8532 - accuracy: 0.2243 - 2s/epoch - 5ms/step\n",
            "Epoch 15/50\n",
            "322/322 - 2s - loss: 3.6432 - accuracy: 0.2554 - 2s/epoch - 5ms/step\n",
            "Epoch 16/50\n",
            "322/322 - 1s - loss: 3.4367 - accuracy: 0.2906 - 1s/epoch - 4ms/step\n",
            "Epoch 17/50\n",
            "322/322 - 1s - loss: 3.2322 - accuracy: 0.3288 - 1s/epoch - 4ms/step\n",
            "Epoch 18/50\n",
            "322/322 - 1s - loss: 3.0338 - accuracy: 0.3714 - 1s/epoch - 5ms/step\n",
            "Epoch 19/50\n",
            "322/322 - 1s - loss: 2.8370 - accuracy: 0.4076 - 1s/epoch - 4ms/step\n",
            "Epoch 20/50\n",
            "322/322 - 2s - loss: 2.6472 - accuracy: 0.4521 - 2s/epoch - 5ms/step\n",
            "Epoch 21/50\n",
            "322/322 - 2s - loss: 2.4655 - accuracy: 0.4945 - 2s/epoch - 5ms/step\n",
            "Epoch 22/50\n",
            "322/322 - 2s - loss: 2.2953 - accuracy: 0.5304 - 2s/epoch - 5ms/step\n",
            "Epoch 23/50\n",
            "322/322 - 1s - loss: 2.1303 - accuracy: 0.5727 - 1s/epoch - 5ms/step\n",
            "Epoch 24/50\n",
            "322/322 - 1s - loss: 1.9761 - accuracy: 0.6038 - 1s/epoch - 4ms/step\n",
            "Epoch 25/50\n",
            "322/322 - 1s - loss: 1.8309 - accuracy: 0.6359 - 1s/epoch - 4ms/step\n",
            "Epoch 26/50\n",
            "322/322 - 2s - loss: 1.6938 - accuracy: 0.6722 - 2s/epoch - 5ms/step\n",
            "Epoch 27/50\n",
            "322/322 - 2s - loss: 1.5657 - accuracy: 0.6937 - 2s/epoch - 5ms/step\n",
            "Epoch 28/50\n",
            "322/322 - 1s - loss: 1.4457 - accuracy: 0.7246 - 1s/epoch - 4ms/step\n",
            "Epoch 29/50\n",
            "322/322 - 2s - loss: 1.3334 - accuracy: 0.7477 - 2s/epoch - 5ms/step\n",
            "Epoch 30/50\n",
            "322/322 - 2s - loss: 1.2291 - accuracy: 0.7711 - 2s/epoch - 5ms/step\n",
            "Epoch 31/50\n",
            "322/322 - 2s - loss: 1.1296 - accuracy: 0.7949 - 2s/epoch - 5ms/step\n",
            "Epoch 32/50\n",
            "322/322 - 1s - loss: 1.0405 - accuracy: 0.8147 - 1s/epoch - 5ms/step\n",
            "Epoch 33/50\n",
            "322/322 - 1s - loss: 0.9552 - accuracy: 0.8334 - 1s/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "322/322 - 1s - loss: 0.8782 - accuracy: 0.8508 - 1s/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "322/322 - 2s - loss: 0.8051 - accuracy: 0.8638 - 2s/epoch - 5ms/step\n",
            "Epoch 36/50\n",
            "322/322 - 2s - loss: 0.7392 - accuracy: 0.8772 - 2s/epoch - 5ms/step\n",
            "Epoch 37/50\n",
            "322/322 - 1s - loss: 0.6786 - accuracy: 0.8899 - 1s/epoch - 5ms/step\n",
            "Epoch 38/50\n",
            "322/322 - 1s - loss: 0.6216 - accuracy: 0.8974 - 1s/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "322/322 - 1s - loss: 0.5708 - accuracy: 0.9075 - 1s/epoch - 4ms/step\n",
            "Epoch 40/50\n",
            "322/322 - 1s - loss: 0.5245 - accuracy: 0.9159 - 1s/epoch - 4ms/step\n",
            "Epoch 41/50\n",
            "322/322 - 1s - loss: 0.4825 - accuracy: 0.9209 - 1s/epoch - 4ms/step\n",
            "Epoch 42/50\n",
            "322/322 - 2s - loss: 0.4436 - accuracy: 0.9260 - 2s/epoch - 5ms/step\n",
            "Epoch 43/50\n",
            "322/322 - 1s - loss: 0.4078 - accuracy: 0.9324 - 1s/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "322/322 - 1s - loss: 0.3787 - accuracy: 0.9343 - 1s/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "322/322 - 1s - loss: 0.3481 - accuracy: 0.9397 - 1s/epoch - 4ms/step\n",
            "Epoch 46/50\n",
            "322/322 - 1s - loss: 0.3219 - accuracy: 0.9426 - 1s/epoch - 4ms/step\n",
            "Epoch 47/50\n",
            "322/322 - 1s - loss: 0.3012 - accuracy: 0.9448 - 1s/epoch - 4ms/step\n",
            "Epoch 48/50\n",
            "322/322 - 2s - loss: 0.2813 - accuracy: 0.9454 - 2s/epoch - 5ms/step\n",
            "Epoch 49/50\n",
            "322/322 - 1s - loss: 0.2630 - accuracy: 0.9478 - 1s/epoch - 5ms/step\n",
            "Epoch 50/50\n",
            "322/322 - 1s - loss: 0.2473 - accuracy: 0.9508 - 1s/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ZRPWhVgkUOpQ",
        "outputId": "ef27e05e-48d1-4a14-dbbf-009a99484498"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7df0cc0bd0f0>]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the trained model\n",
        "def generate_text(text_input, next_words, model, max_sequence_length, tokenizer):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([text_input])[0]\n",
        "        print(token_list)\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        text_input += \" \" + output_word\n",
        "    return text_input\n",
        "\n",
        "# Example of text generation\n",
        "text_input = \"There now is your insular\"\n",
        "generated_text = generate_text(text_input, next_words=20, model=model, max_sequence_length=max_sequence_len, tokenizer=tokenizer)\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCYsTgHTUQ_d",
        "outputId": "76b27415-16b6-4f05-b307-525e3551a155"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[28, 36, 20, 87, 1004]\n",
            "1/1 [==============================] - 0s 370ms/step\n",
            "[28, 36, 20, 87, 1004, 320]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1]\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3, 87]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3, 87, 62]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3, 87, 62, 557]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3, 87, 62, 557, 3]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3, 87, 62, 557, 3, 1]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3, 87, 62, 557, 3, 1, 698]\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3, 87, 62, 557, 3, 1, 698, 67]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3, 87, 62, 557, 3, 1, 698, 67, 8]\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "[28, 36, 20, 87, 1004, 320, 4, 1, 1005, 1006, 113, 40, 1, 208, 3, 87, 62, 557, 3, 1, 698, 67, 8, 43]\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "There now is your insular city of the manhattoes belted round by the whale and your head civilized and the crossed sea it had a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generated_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6bZmXN3RXVVy",
        "outputId": "ee46488b-08eb-4f88-fe65-8318d29d5f87"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'There now is your insular city of the manhattoes belted round by the whale and your head civilized and the crossed sea it had a'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Seed Text:**\n",
        "##*There now is your insular*\n",
        "\n",
        "# **Generated Text- Keras + LSTM :**\n",
        "##*There now is your insular city of the manhattoes belted round by the whale and your head civilized and the crossed sea it had a*"
      ],
      "metadata": {
        "id": "t1auCep_bBqc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem 2: 3. Transfer Learning: Text generation model developed using word2vec word embeddings**"
      ],
      "metadata": {
        "id": "KqhH4mMJf-qn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec_model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Load the data\n",
        "#with open('/content/drive/MyDrive/DeepLearning/HW/HW4/mobydick_ch04.txt', 'r', encoding='utf-8') as file:\n",
        "#    text = file.read()\n",
        "\n",
        "# Tokenization and cleaning\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([tokens])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "input_sequences = []\n",
        "for line in tokens.split('\\n'):\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
        "input_sequence = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "X = input_sequence[:, :-1]\n",
        "y = input_sequence[:,-1]\n",
        "\n",
        "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))\n",
        "\n",
        "# Create an embedding matrix using Word2Vec embeddings\n",
        "embedding_dim = 300\n",
        "embedding_matrix = np.zeros((total_words, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in word2vec_model:\n",
        "        embedding_matrix[i] = word2vec_model[word]\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=total_words, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_sequence_len-1, trainable=False))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X, y, epochs=50, verbose=2)\n"
      ],
      "metadata": {
        "id": "O9Zxt0xAuka8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23b6fde-e45f-41a5-ec38-f0647ea91a53"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 16, 300)           818400    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 150)               270600    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2728)              411928    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1500928 (5.73 MB)\n",
            "Trainable params: 682528 (2.60 MB)\n",
            "Non-trainable params: 818400 (3.12 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "322/322 - 3s - loss: 6.6641 - accuracy: 0.0514 - 3s/epoch - 10ms/step\n",
            "Epoch 2/50\n",
            "322/322 - 1s - loss: 6.1902 - accuracy: 0.0639 - 1s/epoch - 4ms/step\n",
            "Epoch 3/50\n",
            "322/322 - 1s - loss: 5.9905 - accuracy: 0.0852 - 1s/epoch - 4ms/step\n",
            "Epoch 4/50\n",
            "322/322 - 1s - loss: 5.7306 - accuracy: 0.1001 - 1s/epoch - 4ms/step\n",
            "Epoch 5/50\n",
            "322/322 - 1s - loss: 5.4463 - accuracy: 0.1135 - 1s/epoch - 4ms/step\n",
            "Epoch 6/50\n",
            "322/322 - 1s - loss: 5.1438 - accuracy: 0.1236 - 1s/epoch - 4ms/step\n",
            "Epoch 7/50\n",
            "322/322 - 1s - loss: 4.8224 - accuracy: 0.1385 - 1s/epoch - 4ms/step\n",
            "Epoch 8/50\n",
            "322/322 - 1s - loss: 4.4905 - accuracy: 0.1561 - 1s/epoch - 4ms/step\n",
            "Epoch 9/50\n",
            "322/322 - 1s - loss: 4.1604 - accuracy: 0.1804 - 1s/epoch - 4ms/step\n",
            "Epoch 10/50\n",
            "322/322 - 1s - loss: 3.8291 - accuracy: 0.2226 - 1s/epoch - 4ms/step\n",
            "Epoch 11/50\n",
            "322/322 - 1s - loss: 3.5033 - accuracy: 0.2798 - 1s/epoch - 4ms/step\n",
            "Epoch 12/50\n",
            "322/322 - 1s - loss: 3.1880 - accuracy: 0.3443 - 1s/epoch - 4ms/step\n",
            "Epoch 13/50\n",
            "322/322 - 1s - loss: 2.8907 - accuracy: 0.4061 - 1s/epoch - 4ms/step\n",
            "Epoch 14/50\n",
            "322/322 - 1s - loss: 2.6093 - accuracy: 0.4683 - 1s/epoch - 4ms/step\n",
            "Epoch 15/50\n",
            "322/322 - 1s - loss: 2.3541 - accuracy: 0.5234 - 1s/epoch - 4ms/step\n",
            "Epoch 16/50\n",
            "322/322 - 1s - loss: 2.1249 - accuracy: 0.5738 - 1s/epoch - 4ms/step\n",
            "Epoch 17/50\n",
            "322/322 - 1s - loss: 1.9152 - accuracy: 0.6176 - 1s/epoch - 4ms/step\n",
            "Epoch 18/50\n",
            "322/322 - 1s - loss: 1.7289 - accuracy: 0.6591 - 1s/epoch - 4ms/step\n",
            "Epoch 19/50\n",
            "322/322 - 1s - loss: 1.5634 - accuracy: 0.6973 - 1s/epoch - 4ms/step\n",
            "Epoch 20/50\n",
            "322/322 - 1s - loss: 1.4072 - accuracy: 0.7345 - 1s/epoch - 4ms/step\n",
            "Epoch 21/50\n",
            "322/322 - 1s - loss: 1.2684 - accuracy: 0.7635 - 1s/epoch - 4ms/step\n",
            "Epoch 22/50\n",
            "322/322 - 1s - loss: 1.1433 - accuracy: 0.7941 - 1s/epoch - 4ms/step\n",
            "Epoch 23/50\n",
            "322/322 - 1s - loss: 1.0332 - accuracy: 0.8177 - 1s/epoch - 4ms/step\n",
            "Epoch 24/50\n",
            "322/322 - 1s - loss: 0.9317 - accuracy: 0.8400 - 1s/epoch - 4ms/step\n",
            "Epoch 25/50\n",
            "322/322 - 1s - loss: 0.8389 - accuracy: 0.8597 - 1s/epoch - 4ms/step\n",
            "Epoch 26/50\n",
            "322/322 - 1s - loss: 0.7588 - accuracy: 0.8760 - 1s/epoch - 4ms/step\n",
            "Epoch 27/50\n",
            "322/322 - 1s - loss: 0.6834 - accuracy: 0.8897 - 1s/epoch - 4ms/step\n",
            "Epoch 28/50\n",
            "322/322 - 1s - loss: 0.6179 - accuracy: 0.9003 - 1s/epoch - 4ms/step\n",
            "Epoch 29/50\n",
            "322/322 - 1s - loss: 0.5611 - accuracy: 0.9104 - 1s/epoch - 4ms/step\n",
            "Epoch 30/50\n",
            "322/322 - 1s - loss: 0.5107 - accuracy: 0.9186 - 1s/epoch - 4ms/step\n",
            "Epoch 31/50\n",
            "322/322 - 1s - loss: 0.4695 - accuracy: 0.9238 - 1s/epoch - 4ms/step\n",
            "Epoch 32/50\n",
            "322/322 - 1s - loss: 0.4313 - accuracy: 0.9279 - 1s/epoch - 4ms/step\n",
            "Epoch 33/50\n",
            "322/322 - 1s - loss: 0.3970 - accuracy: 0.9314 - 1s/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "322/322 - 1s - loss: 0.3655 - accuracy: 0.9340 - 1s/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "322/322 - 1s - loss: 0.3440 - accuracy: 0.9363 - 1s/epoch - 4ms/step\n",
            "Epoch 36/50\n",
            "322/322 - 1s - loss: 0.3254 - accuracy: 0.9383 - 1s/epoch - 4ms/step\n",
            "Epoch 37/50\n",
            "322/322 - 1s - loss: 0.3018 - accuracy: 0.9407 - 1s/epoch - 4ms/step\n",
            "Epoch 38/50\n",
            "322/322 - 1s - loss: 0.2856 - accuracy: 0.9409 - 1s/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "322/322 - 1s - loss: 0.2720 - accuracy: 0.9415 - 1s/epoch - 4ms/step\n",
            "Epoch 40/50\n",
            "322/322 - 1s - loss: 0.2672 - accuracy: 0.9428 - 1s/epoch - 4ms/step\n",
            "Epoch 41/50\n",
            "322/322 - 1s - loss: 0.2622 - accuracy: 0.9410 - 1s/epoch - 4ms/step\n",
            "Epoch 42/50\n",
            "322/322 - 1s - loss: 0.2451 - accuracy: 0.9424 - 1s/epoch - 4ms/step\n",
            "Epoch 43/50\n",
            "322/322 - 1s - loss: 0.2380 - accuracy: 0.9414 - 1s/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "322/322 - 1s - loss: 0.2310 - accuracy: 0.9430 - 1s/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "322/322 - 1s - loss: 0.2234 - accuracy: 0.9432 - 1s/epoch - 4ms/step\n",
            "Epoch 46/50\n",
            "322/322 - 1s - loss: 0.2154 - accuracy: 0.9439 - 1s/epoch - 4ms/step\n",
            "Epoch 47/50\n",
            "322/322 - 1s - loss: 0.2102 - accuracy: 0.9439 - 1s/epoch - 4ms/step\n",
            "Epoch 48/50\n",
            "322/322 - 1s - loss: 0.2051 - accuracy: 0.9436 - 1s/epoch - 4ms/step\n",
            "Epoch 49/50\n",
            "322/322 - 1s - loss: 0.2017 - accuracy: 0.9438 - 1s/epoch - 4ms/step\n",
            "Epoch 50/50\n",
            "322/322 - 1s - loss: 0.1980 - accuracy: 0.9444 - 1s/epoch - 4ms/step\n",
            "1/1 [==============================] - 0s 324ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "There now is your insular city of the manhattoes belted round by by by the street and the room then the broken and me on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])"
      ],
      "metadata": {
        "id": "EROsIGH5dbm4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "8d5cd796-44f5-4189-88cc-85db5b6b3f77"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7deeecf9cac0>]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text using the trained model with temperature scaling\n",
        "def generate_text(text_input, next_words, model, max_sequence_length, tokenizer, temperature=1.9):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([text_input])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_length-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list)[0]\n",
        "\n",
        "        # Apply temperature scaling\n",
        "        scaled_probs = predicted_probs**(1 / temperature)\n",
        "        normalized_probs = scaled_probs / np.sum(scaled_probs)\n",
        "\n",
        "        # Sample a word based on the scaled probabilities\n",
        "        predicted_index = np.random.choice(len(normalized_probs), p=normalized_probs)\n",
        "\n",
        "        output_word = tokenizer.index_word.get(predicted_index, \"\")\n",
        "        text_input += \" \" + output_word\n",
        "\n",
        "    return text_input\n",
        "\n",
        "# Example of text generation\n",
        "text_input = \"There now is your insular\"\n",
        "generated_text = generate_text(text_input, next_words=20, model=model, max_sequence_length=max_sequence_len, tokenizer=tokenizer)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "ldwu6ntYdpnN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c57125-b407-4b17-eee1-301299ded251"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "There now is your insular lives of something sort come in airth sort of a land probably sea was this most of guise whether so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_text)"
      ],
      "metadata": {
        "id": "yhTibDJuFRPh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34be988b-8a55-41b2-cfe2-c721b83659e2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There now is your insular lives of something sort come in airth sort of a land probably sea was this most of guise whether so\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Seed Text:**\n",
        "##*There now is your insular*\n",
        "\n",
        "# **Generated Text- Word2Vec + LSTM :**\n",
        "##*There now is your insular lives of something sort come in airth sort of a land probably sea was this most of guise whether so*"
      ],
      "metadata": {
        "id": "ZP7OSW83sVTg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dv3oP8tyjxJ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}